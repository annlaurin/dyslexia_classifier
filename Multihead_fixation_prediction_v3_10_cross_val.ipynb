{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444f024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial, reduce\n",
    "import argparse\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from typing import TextIO, Callable, Collection, Dict, Iterator, List, Tuple, Type, TypeVar\n",
    "T = TypeVar(\"T\", bound=\"EyetrackingClassifier\")\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/transformer\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21cf40",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91aec7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "NUM_FEATURES = 14\n",
    "NUM_FIX = 30 \n",
    "NUM_CLASSES = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8823925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def mse_loss(target, input, mask):\n",
    "    out = (input[mask]-target[mask])**2\n",
    "    return out.mean()\n",
    "\n",
    "def mask_with_tokens_3D(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    reduced = torch.any(mask, dim=-1, keepdim=True)\n",
    "    expanded = reduced.expand_as(mask)\n",
    "    return expanded\n",
    "\n",
    "def get_mask_subset_with_prob_3D(mask, prob):\n",
    "    batch, num_fix, num_features, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * num_fix)\n",
    "\n",
    "    num_tokens = mask.sum(dim=-2, keepdim=True)\n",
    "    mask_excess = (mask.cumsum(dim=-2)[:,:,0] > (num_tokens[:,:,0] * prob).ceil())\n",
    "    mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "    rand = torch.rand((batch, num_fix, num_features), device=device).masked_fill(~mask, -1e9)\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-2)\n",
    "    sampled_indices = (sampled_indices[:,:,0] + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "    new_mask = torch.zeros((batch, num_fix + 1), device=device)\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)\n",
    "    new_mask = new_mask[:, 1:].bool()\n",
    "    \n",
    "    return new_mask.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "\n",
    "def prob_mask_like_3D(t, prob):\n",
    "    temp = torch.zeros_like(t[:,:,0]).float().uniform_(0, 1) < prob\n",
    "    return temp.unsqueeze_(2).expand(-1,-1, NUM_FEATURES)\n",
    "    \n",
    "    \n",
    "def pad_group_with_zeros(group, target_rows):\n",
    "    # Calculate the number of rows to add\n",
    "    num_missing_rows = target_rows - len(group)\n",
    "    if num_missing_rows > 0:\n",
    "        # Create a DataFrame with the required number of padding rows\n",
    "        # input padding\n",
    "        zero_rows = pd.DataFrame(0.3333, index=range(num_missing_rows), columns=group.columns)\n",
    "        # Label padding\n",
    "        # zero_rows.iloc[:, 0] = 31\n",
    "        # Concatenate the group with the zero rows\n",
    "        group = pd.concat([group, zero_rows], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "# class ToTensor(object):\n",
    "#     \"\"\"Convert Series in sample to Tensors.\"\"\"\n",
    "\n",
    "#     def __call__(self, sample):\n",
    "#         trial, label = sample['trial'], sample['label']\n",
    "#         trial = torch.from_numpy(trial).float()\n",
    "#         label = torch.from_numpy(label).float()\n",
    "#         return trial, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5178796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPositionalEncoding(nn.Module):\n",
    "    \"\"\"Learnable positional encoding for both features and fixations\n",
    "    Assumes input `x` is of shape [batch_size, fixations, embed_dim]\"\"\"\n",
    "    def __init__(self, fixations = 30, features = None):\n",
    "        super(CustomPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix\n",
    "        self.encoding = nn.Parameter(torch.zeros(fixations, features)).to(device)\n",
    "        nn.init.xavier_uniform_(self.encoding)  # Xavier initialization for better training stability\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_encoding = self.encoding  * mask\n",
    "        else:\n",
    "            pos_encoding = self.encoding\n",
    "        return x + pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de096ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnasPositionalEncoding(nn.Module):\n",
    "    \"\"\"Learnable positional encoding for both features and fixations\n",
    "    Assumes input `x` is of shape [batch_size, fixations, embed_dim]\"\"\"\n",
    "    def __init__(self, fixations = int, features = int):\n",
    "        super(AnnasPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix for fixations\n",
    "        self.fix_encoding = nn.Parameter(torch.zeros(fixations, 1)).to(device)\n",
    "        nn.init.xavier_uniform_(self.fix_encoding)  # Xavier initialization for better training stability\n",
    "        self.fix_encoding = self.fix_encoding.expand(-1, features)\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix for features\n",
    "        self.feat_encoding = nn.Parameter(torch.zeros(1, features)).to(device)\n",
    "        nn.init.xavier_uniform_(self.feat_encoding)  # Xavier initialization for better training stability\n",
    "        self.feat_encoding = self.feat_encoding.expand(fixations, -1)\n",
    "        \n",
    "        self.encoding = self.fix_encoding + self.feat_encoding\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_encoding = self.encoding  * mask\n",
    "        else:\n",
    "            pos_encoding = self.encoding\n",
    "        return x + pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3b7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=278, l2norm_embed = False):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5 if not l2norm_embed else 1.\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.l2norm_embed = l2norm_embed\n",
    "        self.emb = nn.Embedding(max_seq_len, dim)\n",
    "\n",
    "    def forward(self, x, pos = None, seq_start_pos = None, mask = None):\n",
    "        seq_len, device = x.shape[1], x.device\n",
    "        assert seq_len <= self.max_seq_len, f'you are passing in a sequence length of {seq_len} but your absolute positional embedding has a max sequence length of {self.max_seq_len}'\n",
    "\n",
    "        #if not exists(pos):\n",
    "        pos = torch.arange(seq_len, device = device)\n",
    "\n",
    "        #if exists(seq_start_pos):\n",
    "        #    pos = (pos - seq_start_pos[..., None]).clamp(min = 0)\n",
    "\n",
    "        pos_emb = self.emb(pos)\n",
    "        pos_emb = pos_emb * self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_emb = pos_emb * mask\n",
    "            \n",
    "        return l2norm(pos_emb) if self.l2norm_embed else pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=278):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model%2 != 0:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)[:,0:-1]\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to(device)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        pos_enc = self.pe[:, :x.size(1)]\n",
    "        if not(mask == None):\n",
    "            mask = mask.to(device)\n",
    "            pos_enc = pos_enc*mask\n",
    "        return x + pos_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e4065",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f7ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinguisticFeature = Callable[[Tuple[str]], Tuple[torch.Tensor]]\n",
    "\n",
    "# def apply_standardization(x, m, sd):\n",
    "#     nonzero_sd = sd.clone()\n",
    "#     nonzero_sd[sd == 0] = 1\n",
    "#     x = torch.from_numpy(x).float()\n",
    "#     res = (x - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "#     return res\n",
    "\n",
    "def apply_standardization(x, m, sd):\n",
    "    nonzero_sd = sd.clone()\n",
    "    nonzero_sd[sd == 0] = 1\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x_zeros = x[x.sum(dim=(1)) == 0]\n",
    "    x_zeros[x_zeros==0] = -5\n",
    "    x_non_zeros = x[x.sum(dim=(1)) != 0]\n",
    "    x_non_zeros = (x_non_zeros - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "    res = torch.cat((x_non_zeros, x_zeros), axis =0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def aggregate_per_subject(subjs, y_preds, y_preds_class, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_preds_class_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_class_subj = y_preds_class[subjs == subj]\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "        if sum(y_pred_class_subj) >= (len(y_pred_class_subj) / 2):\n",
    "            y_preds_class_subj.append(1)\n",
    "        else:\n",
    "            y_preds_class_subj.append(0)\n",
    "    return subjs_subj, y_preds_subj, y_preds_class_subj, y_trues_subj\n",
    "\n",
    "def getmeansd(dataset, batch: bool = False):  # removing rows of 0s\n",
    "    if batch:\n",
    "        # Anna added preprocessing from ndarray to torch\n",
    "        tensors = [X for X, _, _, _ in dataset]  #torch.from_numpy(X).float()\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=(1,2)) != 0]   #tensors[tensors.sum(dim=(1, 2)) != 0]\n",
    "        # remove rows of 0s from the computation\n",
    "        sentences, timesteps, features = tensors.size()\n",
    "        subset = tensors.sum(dim=(2)) != 0\n",
    "        subset = subset.view(sentences, timesteps, 1)\n",
    "        subset = subset.expand(sentences, timesteps, features)\n",
    "        result = tensors[subset].view(-1, features) \n",
    "        \n",
    "        means = torch.mean(result, dim=(0))\n",
    "        sd = torch.std(result, dim=(0))\n",
    "        return means, sd\n",
    "    else:\n",
    "        tensors = [torch.from_numpy(X).float() for X, _, _, _ in dataset] # Anna added , was [X for X, _, _ in dataset]\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=1) != 0]\n",
    "        means = torch.mean(tensors, 0)\n",
    "        sd = torch.std(tensors, 0)\n",
    "        return means, sd\n",
    "    \n",
    "    \n",
    "# def get_params(paramdict) -> dict:\n",
    "#     selected_pars = dict()\n",
    "#     for k in paramdict:\n",
    "#         selected_pars[k] = random.sample(list(paramdict[k]), 1)[0]\n",
    "#     return selected_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81deb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_speed_per_subject(subjs, y_preds, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    #y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "\n",
    "    return subjs_subj, y_preds_subj, y_trues_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e747c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataPreprocessor(Dataset):\n",
    "    \"\"\"Dataset with the long-format sequence of fixations made during reading by dyslexic \n",
    "    and normally-developing Russian-speaking monolingual children.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        csv_file, \n",
    "        transform=None, \n",
    "        target_transform=None,  \n",
    "        num_folds: float = 10,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on a label.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # changing dyslexia labels to 0 and 1\n",
    "        if {'group'}.issubset(data.columns):   # not the case for pretrain dataset\n",
    "            data['group'] = data['group'] + 0.5\n",
    "        \n",
    "        # log-transforming frequency\n",
    "        to_transform = ['frequency', 'predictability', 'fix_dur'] #\n",
    "        for column in to_transform:\n",
    "            data[column] = data[column].apply(lambda x: np.log(x) if x > 0 else 0) \n",
    "        \n",
    "        # drop columns we don't use\n",
    "        data = data.drop(columns = ['fix_x', 'fix_y', 'fix_index'])  \n",
    "        \n",
    "        # center reading sopeed in case we need to predict it\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            data['Reading_speed'] = (data['Reading_speed'] - data['Reading_speed'].mean())/data['Reading_speed'].std(ddof=0)\n",
    "        \n",
    "        if {'sex', 'Grade'}.issubset(data.columns):\n",
    "            data = data.drop(columns = ['sex', 'Grade'])\n",
    "            \n",
    "        convert_columns = ['direction']\n",
    "        \n",
    "        if {'IQ', 'Sound_detection', 'Sound_change'}.issubset(data.columns):\n",
    "            data = data.drop(columns = ['IQ', 'Sound_detection', 'Sound_change'])\n",
    "        \n",
    "        for column in convert_columns:\n",
    "            prefix = column + '_dummy'\n",
    "            data = pd.concat([data, pd.get_dummies(data[column], \n",
    "                                    prefix=prefix)], axis=1)\n",
    "            data = data.drop(columns = column)\n",
    "\n",
    "        data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "\n",
    "            \n",
    "        # rearrange columns (I need demogrpahic information to come last)\n",
    "#         cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur', 'landing', 'word_length',\n",
    "#                  'predictability', 'frequency', 'number.morphemes', 'next_fix_dist',\n",
    "#                  'sac_ampl', 'sac_angle', 'sac_vel', 'rel.position', 'direction_dummy_DOWN',\n",
    "#                  'direction_dummy_LEFT', 'direction_dummy_RIGHT', 'direction_dummy_UP',\n",
    "#                  'sex', 'Age', 'Grade_dummy_1', 'Grade_dummy_2', 'Grade_dummy_3', 'Grade_dummy_4',\n",
    "#                  'Grade_dummy_5', 'Grade_dummy_6']\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur',\n",
    "                   'landing', 'word_length', 'predictability', 'frequency', \n",
    "                    'number.morphemes', 'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                    'sac_vel', 'rel.position', 'direction_dummy_LEFT', \n",
    "                    'direction_dummy_RIGHT', 'direction_dummy_DOWN'] # temporary\n",
    "        else:\n",
    "            cols = ['item', 'subj', 'fix_dur',\n",
    "                   'landing', 'word_length', 'predictability', 'frequency', \n",
    "                    'number.morphemes', 'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                    'sac_vel', 'rel.position', 'direction_dummy_LEFT', \n",
    "                    'direction_dummy_RIGHT', 'direction_dummy_DOWN'] # temporary\n",
    "        data = data[cols]\n",
    "        \n",
    "        # Record features that are used for prediction\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            self._features = [i for i in data.columns if i not in ['group', 'item', 'subj', 'Reading_speed']]\n",
    "        else:\n",
    "            self._features = [i for i in data.columns if i not in ['item', 'subj']]\n",
    "        self._data = pd.DataFrame()\n",
    "        # Add sentence IDs and subject IDs\n",
    "        self._data[\"sn\"] = data[\"item\"]\n",
    "        self._data[\"subj\"] = data[\"subj\"]\n",
    "        # Add labels\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            self._data[\"group\"] = data[\"group\"]\n",
    "            self._data[\"reading_speed\"] = data[\"Reading_speed\"]\n",
    "        else:\n",
    "            self._data[\"group\"] = -1\n",
    "            self._data[\"reading_speed\"] = -1\n",
    "        \n",
    "        # Add features used for prediction\n",
    "        for feature in self._features:\n",
    "            self._data[feature] = data[feature]\n",
    "\n",
    "#       # Distribute subjects across stratified folds\n",
    "        self._num_folds = num_folds\n",
    "        self._folds = [[] for _ in range(num_folds)]\n",
    "        just_subjects = self._data[\"subj\"].unique()\n",
    "        random.shuffle(just_subjects)\n",
    "        for i, subj in enumerate(just_subjects):\n",
    "            self._folds[i % num_folds].append(subj)\n",
    "#         dyslexic_subjects = self._data[self._data[\"group\"] == 1][\"subj\"].unique()\n",
    "#         control_subjects = self._data[self._data[\"group\"] == 0][\"subj\"].unique()\n",
    "#         random.shuffle(dyslexic_subjects)\n",
    "#         random.shuffle(control_subjects)\n",
    "#         for i, subj in enumerate(dyslexic_subjects):\n",
    "#             self._folds[i % num_folds].append(subj)\n",
    "#         for i, subj in enumerate(control_subjects):\n",
    "#             self._folds[num_folds - 1 - i % num_folds].append(subj)\n",
    "        for fold in self._folds:\n",
    "            random.shuffle(fold)\n",
    "\n",
    "    def _iter_trials(self, folds: Collection[int]) -> Iterator[pd.DataFrame]:\n",
    "        # Iterate over all folds\n",
    "        for fold in folds:\n",
    "            # Iterate over all subjects in the fold\n",
    "            for subj in self._folds[fold]:       # Anna: subj in fold?\n",
    "                subj_data = self._data[self._data[\"subj\"] == subj]\n",
    "                # Iterate over all sentences this subject read\n",
    "                for sn in subj_data[\"sn\"].unique():\n",
    "                    trial_data = subj_data[subj_data[\"sn\"] == sn]\n",
    "                    yield trial_data\n",
    "                    \n",
    "                    \n",
    "    def iter_folds(\n",
    "        self, folds: Collection[int]) -> Iterator[Tuple[torch.Tensor, torch.Tensor, int]]:\n",
    "        for trial_data in self._iter_trials(folds):\n",
    "            predictors = trial_data[self._features].to_numpy()\n",
    "            #predictors = np.reshape(predictors, (int(len(predictors)/278), 278, predictors.shape[1]))\n",
    "            label = trial_data[\"group\"].unique().item()\n",
    "            subj = trial_data[\"subj\"].unique().item()\n",
    "            reading_speed = trial_data[\"reading_speed\"].unique().item()\n",
    "            #  X = (time_steps, features)\n",
    "            X = predictors\n",
    "            y = torch.tensor(label, dtype=torch.float)\n",
    "            rs = torch.tensor(reading_speed , dtype=torch.float)\n",
    "            yield X, y, subj, rs\n",
    "                    \n",
    "\n",
    "    @property\n",
    "    def num_features(self) -> int:\n",
    "        \"\"\"Number of features per word (excluding word vector dimensions).\"\"\"\n",
    "        return len(self._features)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def max_number_of_sentences(self):\n",
    "        data_copy = self._data.copy()\n",
    "        max_s_count = data_copy.groupby(by=\"subj\").sn.unique()\n",
    "        return max([len(x) for x in max_s_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c918bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprocessor: EyetrackingDataPreprocessor,\n",
    "       # word_vector_model: WordVectorModel,\n",
    "        folds: Collection[int],\n",
    "        batch_subjects: bool = False,\n",
    "    ):\n",
    "        self.sentences = list(preprocessor.iter_folds(folds))\n",
    "        self._subjects = list(np.unique([subj for _, _, subj, _ in self.sentences]))\n",
    "        self.num_features = preprocessor.num_features# + word_vector_model.dimensions()\n",
    "        self.batch_subjects = batch_subjects\n",
    "        #self.max_sentence_length = preprocessor.max_sentence_length\n",
    "        self.max_number_of_sentences = preprocessor.max_number_of_sentences\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        if self.batch_subjects:\n",
    "            subject = self._subjects[index]\n",
    "            subject_sentences = [\n",
    "                (X, y, subj, rs) for X, y, subj, rs in self.sentences if subj == subject\n",
    "            ]\n",
    "            X = torch.stack([torch.FloatTensor(X) for X, _, _, _ in subject_sentences]) #[X for X, _, _ in subject_sentences] #torch.FloatTensor([X for X, _, _ in subject_sentences])\n",
    "            y = torch.stack([y for _, y, _, _ in subject_sentences]).unique().squeeze() \n",
    "            rs = torch.stack([rs for _, _, _, rs in subject_sentences]).unique().squeeze()\n",
    "            return X, y, subject, rs\n",
    "\n",
    "        else:\n",
    "            X, y, subj, rs = self.sentences[index] \n",
    "            return X, y, subj, rs\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.batch_subjects:\n",
    "            return len(self._subjects)\n",
    "        else:\n",
    "            return len(self.sentences)\n",
    "\n",
    "    def standardize(self, mean: torch.Tensor, sd: torch.Tensor):\n",
    "        self.sentences = [\n",
    "            (apply_standardization(X, mean, sd), y, subj, rs)\n",
    "            for X, y, subj, rs in self.sentences\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aec3c4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f129fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):  \n",
    "    def __init__(self,\n",
    "                dim_upscale = int,\n",
    "                inner_dim_upscale = int,\n",
    "                num_heads = int, \n",
    "                num_layers = int, \n",
    "                dropout = 0\n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.dim_upscale = dim_upscale\n",
    "        self.inner_dim_upscale = inner_dim_upscale\n",
    "        \n",
    "        # layer norm for multi-head attention\n",
    "        self.attn_layer_norm = nn.LayerNorm(self.dim_upscale)\n",
    "        # layer norm for feedforward network\n",
    "        self.ffn_layer_norm = nn.LayerNorm(self.dim_upscale)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim = self.dim_upscale,  \n",
    "                                                 num_heads = self.num_heads, \n",
    "                                                 bias = True,\n",
    "                                                 batch_first = True)\n",
    "        # feed forward\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(self.dim_upscale, self.inner_dim_upscale, bias = True),\n",
    "            nn.LayerNorm(self.inner_dim_upscale),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.inner_dim_upscale, self.dim_upscale, bias = True)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "        # pass embeddings through multi-head attention\n",
    "        x, attn_probs = self.attention(src, src, src, src_mask)\n",
    "\n",
    "        # residual add and norm\n",
    "        first_out = self.attn_layer_norm(x + src)\n",
    "\n",
    "        # position-wise feed-forward network\n",
    "        x2 = self.ff(first_out)\n",
    "\n",
    "        # residual add and norm\n",
    "        second_out = self.ffn_layer_norm(x2 + first_out)\n",
    "\n",
    "        return second_out, attn_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4390ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                dim_upscale = int,\n",
    "                inner_dim_upscale = int,\n",
    "                num_heads = int, \n",
    "                num_layers = int, \n",
    "                dropout = 0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.dim_upscale = dim_upscale\n",
    "        self.inner_dim_upscale = inner_dim_upscale\n",
    "        \n",
    "        # create n_layers encoders \n",
    "        self.layers = nn.ModuleList([EncoderLayer(\n",
    "                                    dim_upscale = self.dim_upscale,\n",
    "                                    num_heads = self.num_heads, \n",
    "                                    inner_dim_upscale = self.inner_dim_upscale,\n",
    "                                    dropout = self.dropout)\n",
    "                                     for layer in range(self.num_layers)])\n",
    "\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "\n",
    "        # pass the sequences through each encoder\n",
    "        for layer in self.layers:\n",
    "            src, attn_probs = layer(src, src_mask)\n",
    "\n",
    "        self.attn_probs = attn_probs\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9912ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, config):\n",
    "        super().__init__()\n",
    "        self.initialize_model(input_size, config)\n",
    "        self.config = config\n",
    "\n",
    "    def initialize_model(self, input_size: int, config):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _predict(self, X: torch.Tensor, identity: bool = False, subj_mean: bool = False, pretrain: bool = False) -> torch.Tensor:\n",
    "        if pretrain:\n",
    "            y_preds, labels, mask = self(X, identity, pretrain=True)\n",
    "            return y_preds, labels, mask\n",
    "        else:\n",
    "            y_preds, labels, mask = self(X, identity, pretrain)\n",
    "            return y_preds, labels, mask\n",
    "        \n",
    "    @classmethod\n",
    "    def train_model(\n",
    "        cls: Type[T],\n",
    "        data: EyetrackingDataset,\n",
    "        min_epochs: int = 15,\n",
    "        max_epochs: int = 300,\n",
    "        dev_data: EyetrackingDataset = None,\n",
    "        device: str = \"cuda\",\n",
    "        config = None,\n",
    "        patience = 20,\n",
    "        pretrained_model: T = None,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[T, int]:\n",
    "        model = pretrained_model or cls(data.num_features, config, **kwargs) \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        optimizer = Adam(model.parameters(), lr=config[\"lr\"])\n",
    "        epoch_count = 0\n",
    "        best_losses = [float(\"inf\")] * patience\n",
    "        for epoch in range(max_epochs):\n",
    "            # reshuffle data in each epoch\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                data,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "            )\n",
    "            epoch_count += 1\n",
    "            epoch_loss = 0\n",
    "            for X, _, _, _ in loader:\n",
    "                X = X.to(device)\n",
    "                train_preds, labels, mask = model._predict(X, identity = False) \n",
    "                loss = mse_loss(\n",
    "                    labels,\n",
    "                    train_preds,\n",
    "                    mask\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            #avg_loss = epoch_loss/math.ceil(len(loader.dataset)/BATCH_SIZE)  # TODO: delete later\n",
    "            #print(f\"Epoch {epoch} done. Loss: {avg_loss}\")\n",
    "            \n",
    "            if dev_data is not None:\n",
    "                dev_loss = model.evaluate(dev_data, metric=\"loss\", device=device)\n",
    "                model.train()\n",
    "                # print(f\"Dev loss: {dev_accuracy} in Epoch {epoch}\")\n",
    "                if epoch > min_epochs and all(dev_loss > i for i in best_losses):\n",
    "                    epoch_count -= patience - best_losses.index(min(best_losses))\n",
    "                    break\n",
    "                else:\n",
    "                    best_losses.pop(0)\n",
    "                    best_losses.append(dev_loss)\n",
    "        return model\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        data: EyetrackingDataset,\n",
    "        metric: str = \"loss\",\n",
    "        device: str = \"cuda\",\n",
    "    ) -> Tuple[float, float, float, float]:\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        loader = torch.utils.data.DataLoader(data, batch_size=BATCH_SIZE)\n",
    "        loss = 0\n",
    "        for X, _, _, _ in loader:\n",
    "            X = X.to(device)\n",
    "            dev_preds, labels, mask = self._predict(X, identity = False)\n",
    "            dloss = mse_loss(\n",
    "                labels,\n",
    "                dev_preds,\n",
    "                mask\n",
    "            )\n",
    "            loss += dloss.item() \n",
    "        avg_loss = loss /math.ceil(len(loader.dataset)/BATCH_SIZE) \n",
    "        if metric == \"loss\":\n",
    "            return avg_loss\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric '{metric}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "675e2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(EyetrackingClassifier):\n",
    "    def initialize_model(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        config,\n",
    "        embed_dim = NUM_FIX,\n",
    "        d_model = NUM_FEATURES,\n",
    "        dim_upscale = 128,\n",
    "        inner_dim_upscale = 4*128,\n",
    "        num_heads = 1, \n",
    "        num_layers = 1, \n",
    "        dropout = 0.15,\n",
    "        mask_prob = 0.2,\n",
    "        pad_token_id = -5,\n",
    "        mask_ignore_token_ids = []\n",
    "        ):\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.d_model = d_model\n",
    "        self.mask_prob = config[\"mask_prob\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.dropout = config[\"dropout\"]\n",
    "        self.dim_upscale = config[\"upscale_dim\"]\n",
    "        self.inner_dim_upscale = config[\"inner_dim\"]\n",
    "\n",
    "        # token ids\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_ignore_token_ids = set([*mask_ignore_token_ids, self.pad_token_id])\n",
    "        \n",
    "        self.positional_encoding = AnnasPositionalEncoding(fixations = self.embed_dim, \n",
    "                                                           features = self.d_model)\n",
    "        \n",
    "        self.upscale = nn.Linear(self.d_model, self.dim_upscale, bias = True)\n",
    "        self.downscale = nn.Linear(self.dim_upscale, self.d_model, bias = True)\n",
    "        \n",
    "        self.encoder = Encoder(dim_upscale = self.dim_upscale, \n",
    "                               num_heads = self.num_heads, \n",
    "                               num_layers = self.num_layers,\n",
    "                               inner_dim_upscale = self.inner_dim_upscale, \n",
    "                               dropout = self.dropout)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, identity = False, pretrain: bool = False):\n",
    "        \n",
    "        # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "        # also do not include these special tokens in the tokens chosen at random\n",
    "        no_mask = mask_with_tokens_3D(input, self.mask_ignore_token_ids) \n",
    "        mask = get_mask_subset_with_prob_3D(~no_mask, self.mask_prob)\n",
    "        hidden = no_mask + mask # all elements that the model will not attend to\n",
    "\n",
    "        masked_seq = input.clone().detach().to(device)\n",
    "        \n",
    "        #  positional encoding\n",
    "        masked_seq_pos = self.positional_encoding(masked_seq, mask = None) #for hidden fixations ~ no_mask\n",
    "\n",
    "        # derive labels to predict\n",
    "        labels = input.masked_fill(~mask, self.pad_token_id)\n",
    "    \n",
    "        if identity:\n",
    "            attn_mask = no_mask[:,:,0]\n",
    "        else:\n",
    "            attn_mask = hidden[:,:,0]\n",
    "        \n",
    "        # Upscaling\n",
    "        masked_seq_upscaled = self.upscale(masked_seq_pos)\n",
    "        \n",
    "        # Encoder\n",
    "        out = self.encoder(masked_seq_upscaled, \n",
    "                           attn_mask)  \n",
    "        out = self.downscale(out)\n",
    "\n",
    "        return out, labels, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca2ca8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2539b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = {\n",
    "    \"transformer\": {\n",
    "        \"lr\": np.linspace(1e-03, 1e-05, num=15), \n",
    "        \"num_layers\": [1, 2, 4, 8, 16],      \n",
    "        \"dropout\": np.linspace(0, 0.5, num=15),\n",
    "        \"mask_prob\": np.linspace(0, 0.5, num=15),\n",
    "        \"upscale_dim\": [14, 32, 64, 128, 256, 512, 1024],\n",
    "        # \"num_heads\" is specified in get_params_nested()\n",
    "        # \"inner_dim\" is specified in get_params_nested()\n",
    "    }\n",
    "}\n",
    "\n",
    "nested_space = {\n",
    "    \"14\": [1, 2, 7, 14],\n",
    "\t\"32\": [1, 4, 8, 16, 32],\n",
    "\t\"64\": [1, 8, 16, 32, 64],\n",
    "\t\"128\": [1, 8, 32, 64, 128],\n",
    "\t\"256\": [1, 32, 64, 128, 256],\n",
    "\t\"512\": [32, 64, 128, 256, 512],\n",
    "\t\"1024\": [32, 64, 128, 256, 512], \n",
    "}\n",
    "\n",
    "\n",
    "def get_params_nested(paramdict, nested) -> dict:\n",
    "    selected_pars = dict()\n",
    "    for k in paramdict:\n",
    "        selected_pars[k] = random.sample(list(paramdict[k]), 1)[0] \n",
    "    factor = [1, 2, 4, 8]    \n",
    "    if selected_pars[\"upscale_dim\"] == 14:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"14\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([14*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 32:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"32\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([32*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 64:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"64\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([64*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 128:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"128\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([128*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 256:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"256\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([256*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 512:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"512\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([512*x for x in factor], 1)[0]\n",
    "    if selected_pars[\"upscale_dim\"] == 1024:\n",
    "        selected_pars[\"num_heads\"] = random.sample(list(nested[\"1024\"]), 1)[0]\n",
    "        selected_pars[\"inner_dim\"] = random.sample([1024*x for x in factor], 1)[0]\n",
    "        \n",
    "    return selected_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86cccd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune set 0\n",
      "best performing parameter for dev fold  2 :  {'lr': 0.0002928571428571429, 'num_layers': 1, 'dropout': 0.0, 'mask_prob': 0.39285714285714285, 'upscale_dim': 64, 'num_heads': 8, 'inner_dim': 128}\n",
      "test fold 0\n",
      "test loss fold 0 : 0.00014099742807245448\n",
      "test fold 1\n",
      "test loss fold 1 : 0.00014598591301461403\n",
      "test fold 3\n",
      "test loss fold 3 : 0.00023352457302702\n",
      "used test params:  [{'lr': 0.0002928571428571429, 'num_layers': 1, 'dropout': 0.0, 'mask_prob': 0.39285714285714285, 'upscale_dim': 64, 'num_heads': 8, 'inner_dim': 128}]\n",
      "mean: 0.0001735026380380295 std: 2.124537500795365e-05\n"
     ]
    }
   ],
   "source": [
    "# default: --no-tune --wordvectors none --model cnn --subjpred\n",
    "parser = argparse.ArgumentParser(description=\"Run Russian Eye-Movement Pretraining\")\n",
    "parser.add_argument(\"--model\", dest=\"model\")\n",
    "parser.add_argument(\"--tunesets\", type=int, default=1000)\n",
    "parser.add_argument(\"--tune\", dest=\"tune\", action=\"store_true\")\n",
    "parser.add_argument(\"--no-tune\", dest=\"tune\", action=\"store_false\")\n",
    "parser.add_argument(\"--pretrain\", dest=\"pretrain\", action=\"store_true\")\n",
    "parser.add_argument(\"--seed\", dest=\"seed\", type=int, default=42)\n",
    "parser.add_argument(\"--cuda\", dest=\"cudaid\", default=0)\n",
    "parser.set_defaults(tune=True) \n",
    "parser.set_defaults(model = \"transformer\")\n",
    "args = parser.parse_args(args=[]) # modified to work with jupyter notebook\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if args.model == \"transformer\":\n",
    "    MODEL_CLASS = TransformerClassifier \n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    device = torch.device(f'cuda:{args.cudaid}')\n",
    "    \n",
    "NUM_FOLDS = 10\n",
    "NUM_TUNE_SETS = args.tunesets\n",
    "tune = args.tune\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "BATCH_SUBJECTS = False\n",
    "\n",
    "file = \"data/30fixations_RSC_and_children.csv\" # combined: children (293) and adults (114), N = 407\n",
    "\n",
    "\n",
    "NUM_FOLDS = 4\n",
    "NUM_TUNE_SETS = 2\n",
    "\n",
    "if tune:\n",
    "    used_test_params = []\n",
    "    parameter_sample = [\n",
    "        get_params_nested(hyperparameter_space[\"transformer\"], nested_space) for _ in range(NUM_TUNE_SETS)\n",
    "    ]\n",
    "\n",
    "tprs_folds = {}\n",
    "    \n",
    "\n",
    "# load and preprocess data for training\n",
    "preprocessor = EyetrackingDataPreprocessor(\n",
    "    csv_file = file, \n",
    "   num_folds = NUM_FOLDS\n",
    ")\n",
    "\n",
    "test_accuracies = []\n",
    "\n",
    "dev_fold = 2   # dev fold stays the same\n",
    "parameter_evaluations = np.zeros(shape=(NUM_FOLDS, NUM_TUNE_SETS))\n",
    "if tune:\n",
    "    train_folds = [\n",
    "        fold\n",
    "        for fold in range(NUM_FOLDS)\n",
    "        if fold != dev_fold\n",
    "    ]\n",
    "    train_dataset = EyetrackingDataset(\n",
    "        preprocessor,\n",
    "        folds=train_folds,\n",
    "        batch_subjects=BATCH_SUBJECTS,\n",
    "    )\n",
    "    mean, sd = getmeansd(train_dataset, batch=BATCH_SUBJECTS)\n",
    "    train_dataset.standardize(mean, sd)\n",
    "    dev_dataset = EyetrackingDataset(\n",
    "        preprocessor,\n",
    "        folds=[dev_fold],\n",
    "        batch_subjects=BATCH_SUBJECTS,\n",
    "    )\n",
    "    dev_dataset.standardize(mean, sd)\n",
    "    for tune_set in range(NUM_TUNE_SETS):\n",
    "        running_model = copy.deepcopy(MODEL_CLASS)\n",
    "        if tune_set%100 == 0:\n",
    "            print(f'tune set {tune_set}')\n",
    "        if args.pretrain:\n",
    "            pretrained_model = next(pretrained_models)\n",
    "        else:\n",
    "            pretrained_model = None\n",
    "        model = None\n",
    "        model = running_model.train_model(\n",
    "            train_dataset,\n",
    "            min_epochs=15,\n",
    "            max_epochs=300,\n",
    "            dev_data=dev_dataset,\n",
    "            pretrained_model=pretrained_model,\n",
    "            device=device,\n",
    "            config=parameter_sample[tune_set],\n",
    "        )\n",
    "        tune_accuracy = model.evaluate(\n",
    "            data=dev_dataset,\n",
    "            device=device,\n",
    "            metric=\"loss\"\n",
    "        )\n",
    "        parameter_evaluations[dev_fold, tune_set] = tune_accuracy\n",
    "    # Select best parameter set\n",
    "    mean_dev_loss = np.mean(parameter_evaluations, axis=0)\n",
    "    best_parameter_set = np.argmin(mean_dev_loss)\n",
    "    params_test = parameter_sample[best_parameter_set]\n",
    "    print(f'best performing parameter for dev fold ', dev_fold, \": \", params_test)\n",
    "    used_test_params.append(params_test)\n",
    "    best_pretrained_model = None\n",
    "    \n",
    "# Evaluation    \n",
    "for test_fold in range(NUM_FOLDS):\n",
    "    if dev_fold == test_fold:\n",
    "        continue\n",
    "    print(f'test fold {test_fold}')\n",
    "    running_model = copy.deepcopy(MODEL_CLASS)\n",
    "\n",
    "    train_folds = [\n",
    "        fold for fold in range(NUM_FOLDS) if fold != test_fold and fold != dev_fold\n",
    "    ]\n",
    "\n",
    "    train_dataset = EyetrackingDataset(\n",
    "        preprocessor,\n",
    "        folds=train_folds,\n",
    "        batch_subjects=BATCH_SUBJECTS,\n",
    "    )\n",
    "    mean, sd = getmeansd(train_dataset, batch=BATCH_SUBJECTS)\n",
    "    train_dataset.standardize(mean, sd)\n",
    "    dev_dataset = EyetrackingDataset(\n",
    "        preprocessor,\n",
    "        folds=[dev_fold],\n",
    "        batch_subjects=BATCH_SUBJECTS\n",
    "    )\n",
    "    dev_dataset.standardize(mean, sd)\n",
    "    test_dataset = EyetrackingDataset(\n",
    "        preprocessor,\n",
    "        folds=[test_fold],\n",
    "        batch_subjects=BATCH_SUBJECTS,\n",
    "    )\n",
    "    test_dataset.standardize(mean, sd)\n",
    "    model = running_model.train_model(\n",
    "        train_dataset,\n",
    "        min_epochs=15,\n",
    "        max_epochs=300,\n",
    "        dev_data=dev_dataset,\n",
    "        pretrained_model=best_pretrained_model,\n",
    "        device=device,\n",
    "        config=params_test,\n",
    "    )\n",
    "    #print(f'test accuraccy fold ', test_fold)\n",
    "    test_loss = model.evaluate(\n",
    "        test_dataset,\n",
    "        device=device,\n",
    "        metric=\"loss\",\n",
    "    )\n",
    "    print(\"test loss fold\", test_fold, \":\", test_loss)\n",
    "    test_accuracies.append(test_loss)\n",
    "\n",
    "if tune:\n",
    "    print(\"used test params: \", used_test_params)\n",
    "print(\n",
    "    \"mean:\",\n",
    "    np.mean(test_accuracies, axis=0),\n",
    "    \"std:\",\n",
    "    np.std(test_accuracies, axis=0) / np.sqrt(NUM_FOLDS),\n",
    ")\n",
    "\n",
    "final_scores_mean = np.mean(test_accuracies, axis=0)\n",
    "final_scores_std = np.std(test_accuracies, axis=0) / np.sqrt(NUM_FOLDS-1)\n",
    "time_elapsed = time.time() - start_time\n",
    "out_str = \"\"\n",
    "with open(f\"results.txt\", \"w\") as f:\n",
    "    out_str += f\"${round(final_scores_mean,6):1.6f}\\db{{{round(final_scores_std,6):1.6f}}}$\"\n",
    "    out_str += \"\\n\"\n",
    "    out_str += f\"Time: {time_elapsed:7.2f} seconds.\\n\" \n",
    "    out_str += f\"Test losses: {test_accuracies}\\n\"\n",
    "    out_str += f\"Used test params: {used_test_params}\"\n",
    "    f.write(out_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed749936",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_folds = preprocessor._folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "961dee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor._folds == old_folds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

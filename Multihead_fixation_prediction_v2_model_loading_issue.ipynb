{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "444f024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial, reduce\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "from typing import TextIO, Callable, Collection, Dict, Iterator, List, Tuple, Type, TypeVar\n",
    "T = TypeVar(\"T\", bound=\"EyetrackingClassifier\")\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"checkpoints/transformer/\"\n",
    "if not os.path.isdir(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21cf40",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91aec7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "NUM_FEATURES = 14\n",
    "NUM_FIX = 30 \n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 31\n",
    "BATCH_SUBJECTS = False\n",
    "\n",
    "use_pretrain_dataset = True\n",
    "\n",
    "if use_pretrain_dataset:\n",
    "    file = \"data/30fixations_RSC_and_children.csv\" # combined: children and adults, N = 407\n",
    "else:\n",
    "    file = 'data/30fixations_no_padding_sentence_word_pos.csv' # 293 participants in the fine-tunind dataset, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8823925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def mse_loss(target, input, mask):\n",
    "    out = (input[mask]-target[mask])**2\n",
    "    return out.mean()\n",
    "\n",
    "def mask_with_tokens_3D(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    reduced = torch.any(mask, dim=-1, keepdim=True)\n",
    "    expanded = reduced.expand_as(mask)\n",
    "    return expanded\n",
    "\n",
    "def get_mask_subset_with_prob_3D(mask, prob):\n",
    "    batch, num_fix, num_features, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * num_fix)\n",
    "\n",
    "    num_tokens = mask.sum(dim=-2, keepdim=True)\n",
    "    mask_excess = (mask.cumsum(dim=-2)[:,:,0] > (num_tokens[:,:,0] * prob).ceil())\n",
    "    mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "    rand = torch.rand((batch, num_fix, num_features), device=device).masked_fill(~mask, -1e9)\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-2)\n",
    "    sampled_indices = (sampled_indices[:,:,0] + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "    new_mask = torch.zeros((batch, num_fix + 1), device=device)\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)\n",
    "    new_mask = new_mask[:, 1:].bool()\n",
    "    \n",
    "    return new_mask.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "\n",
    "def prob_mask_like_3D(t, prob):\n",
    "    temp = torch.zeros_like(t[:,:,0]).float().uniform_(0, 1) < prob\n",
    "    return temp.unsqueeze_(2).expand(-1,-1, NUM_FEATURES)\n",
    "    \n",
    "    \n",
    "def pad_group_with_zeros(group, target_rows):\n",
    "    # Calculate the number of rows to add\n",
    "    num_missing_rows = target_rows - len(group)\n",
    "    if num_missing_rows > 0:\n",
    "        # Create a DataFrame with the required number of padding rows\n",
    "        # input padding\n",
    "        zero_rows = pd.DataFrame(0.3333, index=range(num_missing_rows), columns=group.columns)\n",
    "        # Label padding\n",
    "        # zero_rows.iloc[:, 0] = 31\n",
    "        # Concatenate the group with the zero rows\n",
    "        group = pd.concat([group, zero_rows], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert Series in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        trial, label = sample['trial'], sample['label']\n",
    "        trial = torch.from_numpy(trial).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "        return trial, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de096ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnasPositionalEncoding(nn.Module):\n",
    "    \"\"\"Learnable positional encoding for both features and fixations\n",
    "    Assumes input `x` is of shape [batch_size, fixations, embed_dim]\"\"\"\n",
    "    def __init__(self, fixations = int, features = int):\n",
    "        super(AnnasPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix for fixations\n",
    "        self.fix_encoding = nn.Parameter(torch.zeros(fixations, 1)).to(device)\n",
    "        nn.init.xavier_uniform_(self.fix_encoding)  # Xavier initialization for better training stability\n",
    "        self.fix_encoding = self.fix_encoding.expand(-1, features)\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix for features\n",
    "        self.feat_encoding = nn.Parameter(torch.zeros(1, features)).to(device)\n",
    "        nn.init.xavier_uniform_(self.feat_encoding)  # Xavier initialization for better training stability\n",
    "        self.feat_encoding = self.feat_encoding.expand(fixations, -1)\n",
    "        \n",
    "        self.encoding = self.fix_encoding + self.feat_encoding\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_encoding = self.encoding  * mask\n",
    "        else:\n",
    "            pos_encoding = self.encoding\n",
    "        return x + pos_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e4065",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f7ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinguisticFeature = Callable[[Tuple[str]], Tuple[torch.Tensor]]\n",
    "\n",
    "# def apply_standardization(x, m, sd):\n",
    "#     nonzero_sd = sd.clone()\n",
    "#     nonzero_sd[sd == 0] = 1\n",
    "#     x = torch.from_numpy(x).float()\n",
    "#     res = (x - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "#     return res\n",
    "\n",
    "def apply_standardization(x, m, sd):\n",
    "    nonzero_sd = sd.clone()\n",
    "    nonzero_sd[sd == 0] = 1\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x_zeros = x[x.sum(dim=(1)) == 0]\n",
    "    x_zeros[x_zeros==0] = -5\n",
    "    x_non_zeros = x[x.sum(dim=(1)) != 0]\n",
    "    x_non_zeros = (x_non_zeros - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "    res = torch.cat((x_non_zeros, x_zeros), axis =0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def aggregate_per_subject(subjs, y_preds, y_preds_class, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_preds_class_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_class_subj = y_preds_class[subjs == subj]\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "        if sum(y_pred_class_subj) >= (len(y_pred_class_subj) / 2):\n",
    "            y_preds_class_subj.append(1)\n",
    "        else:\n",
    "            y_preds_class_subj.append(0)\n",
    "    return subjs_subj, y_preds_subj, y_preds_class_subj, y_trues_subj\n",
    "\n",
    "def getmeansd(dataset, batch: bool = False):  # removing rows of 0s\n",
    "    if batch:\n",
    "        # Anna added preprocessing from ndarray to torch\n",
    "        tensors = [X for X, _, _, _ in dataset]  #torch.from_numpy(X).float()\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=(1,2)) != 0]   #tensors[tensors.sum(dim=(1, 2)) != 0]\n",
    "        # remove rows of 0s from the computation\n",
    "        sentences, timesteps, features = tensors.size()\n",
    "        subset = tensors.sum(dim=(2)) != 0\n",
    "        subset = subset.view(sentences, timesteps, 1)\n",
    "        subset = subset.expand(sentences, timesteps, features)\n",
    "        result = tensors[subset].view(-1, features) \n",
    "        \n",
    "        means = torch.mean(result, dim=(0))\n",
    "        sd = torch.std(result, dim=(0))\n",
    "        return means, sd\n",
    "    else:\n",
    "        tensors = [torch.from_numpy(X).float() for X, _, _, _ in dataset] # Anna added , was [X for X, _, _ in dataset]\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=1) != 0]\n",
    "        means = torch.mean(tensors, 0)\n",
    "        sd = torch.std(tensors, 0)\n",
    "        return means, sd\n",
    "    \n",
    "    \n",
    "def get_params(paramdict) -> dict:\n",
    "    selected_pars = dict()\n",
    "    for k in paramdict:\n",
    "        selected_pars[k] = random.sample(list(paramdict[k]), 1)[0]\n",
    "    return selected_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81deb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_speed_per_subject(subjs, y_preds, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    #y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "\n",
    "    return subjs_subj, y_preds_subj, y_trues_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e747c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataPreprocessor(Dataset):\n",
    "    \"\"\"Dataset with the long-format sequence of fixations made during reading by dyslexic \n",
    "    and normally-developing Russian-speaking monolingual children.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        csv_file, \n",
    "        transform=None, \n",
    "        target_transform=None,  \n",
    "        num_folds: float = 10,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on a label.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # changing dyslexia labels to 0 and 1\n",
    "        if {'group'}.issubset(data.columns):   # not the case for pretrain dataset\n",
    "            data['group'] = data['group'] + 0.5\n",
    "        \n",
    "        # log-transforming frequency\n",
    "        to_transform = ['frequency', 'predictability', 'fix_dur'] #\n",
    "        for column in to_transform:\n",
    "            data[column] = data[column].apply(lambda x: np.log(x) if x > 0 else 0) \n",
    "        \n",
    "        # drop columns we don't use\n",
    "        data = data.drop(columns = ['fix_x', 'fix_y', 'fix_index'])  \n",
    "        \n",
    "        # center reading sopeed in case we need to predict it\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            data['Reading_speed'] = (data['Reading_speed'] - data['Reading_speed'].mean())/data['Reading_speed'].std(ddof=0)\n",
    "        \n",
    "        if {'sex', 'Grade'}.issubset(data.columns):\n",
    "            data = data.drop(columns = ['sex', 'Grade'])\n",
    "            \n",
    "        convert_columns = ['direction']\n",
    "        \n",
    "        if {'IQ', 'Sound_detection', 'Sound_change'}.issubset(data.columns):\n",
    "            data = data.drop(columns = ['IQ', 'Sound_detection', 'Sound_change'])\n",
    "        \n",
    "        for column in convert_columns:\n",
    "            prefix = column + '_dummy'\n",
    "            data = pd.concat([data, pd.get_dummies(data[column], \n",
    "                                    prefix=prefix)], axis=1)\n",
    "            data = data.drop(columns = column)\n",
    "\n",
    "        data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "\n",
    "            \n",
    "        # rearrange columns (I need demogrpahic information to come last)\n",
    "#         cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur', 'landing', 'word_length',\n",
    "#                  'predictability', 'frequency', 'number.morphemes', 'next_fix_dist',\n",
    "#                  'sac_ampl', 'sac_angle', 'sac_vel', 'rel.position', 'direction_dummy_DOWN',\n",
    "#                  'direction_dummy_LEFT', 'direction_dummy_RIGHT', 'direction_dummy_UP',\n",
    "#                  'sex', 'Age', 'Grade_dummy_1', 'Grade_dummy_2', 'Grade_dummy_3', 'Grade_dummy_4',\n",
    "#                  'Grade_dummy_5', 'Grade_dummy_6']\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur',\n",
    "                   'landing', 'word_length', 'predictability', 'frequency', \n",
    "                    'number.morphemes', 'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                    'sac_vel', 'rel.position', 'direction_dummy_LEFT', \n",
    "                    'direction_dummy_RIGHT', 'direction_dummy_DOWN'] # temporary\n",
    "        else:\n",
    "            cols = ['item', 'subj', 'fix_dur',\n",
    "                   'landing', 'word_length', 'predictability', 'frequency', \n",
    "                    'number.morphemes', 'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                    'sac_vel', 'rel.position', 'direction_dummy_LEFT', \n",
    "                    'direction_dummy_RIGHT', 'direction_dummy_DOWN'] # temporary\n",
    "        data = data[cols]\n",
    "        \n",
    "        # Record features that are used for prediction\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            self._features = [i for i in data.columns if i not in ['group', 'item', 'subj', 'Reading_speed']]\n",
    "        else:\n",
    "            self._features = [i for i in data.columns if i not in ['item', 'subj']]\n",
    "        self._data = pd.DataFrame()\n",
    "        # Add sentence IDs and subject IDs\n",
    "        self._data[\"sn\"] = data[\"item\"]\n",
    "        self._data[\"subj\"] = data[\"subj\"]\n",
    "        # Add labels\n",
    "        if {'Reading_speed'}.issubset(data.columns):\n",
    "            self._data[\"group\"] = data[\"group\"]\n",
    "            self._data[\"reading_speed\"] = data[\"Reading_speed\"]\n",
    "        else:\n",
    "            self._data[\"group\"] = -1\n",
    "            self._data[\"reading_speed\"] = -1\n",
    "        \n",
    "        # Add features used for prediction\n",
    "        for feature in self._features:\n",
    "            self._data[feature] = data[feature]\n",
    "\n",
    "#         # Distribute subjects across stratified folds\n",
    "        self._num_folds = num_folds\n",
    "        self._folds = [[] for _ in range(num_folds)]\n",
    "        just_subjects = self._data[\"subj\"].unique()\n",
    "        random.shuffle(just_subjects)\n",
    "        for i, subj in enumerate(just_subjects):\n",
    "            self._folds[i % num_folds].append(subj)\n",
    "#         dyslexic_subjects = self._data[self._data[\"group\"] == 1][\"subj\"].unique()\n",
    "#         control_subjects = self._data[self._data[\"group\"] == 0][\"subj\"].unique()\n",
    "#         random.shuffle(dyslexic_subjects)\n",
    "#         random.shuffle(control_subjects)\n",
    "#         for i, subj in enumerate(dyslexic_subjects):\n",
    "#             self._folds[i % num_folds].append(subj)\n",
    "#         for i, subj in enumerate(control_subjects):\n",
    "#             self._folds[num_folds - 1 - i % num_folds].append(subj)\n",
    "        for fold in self._folds:\n",
    "            random.shuffle(fold)\n",
    "\n",
    "    def _iter_trials(self, folds: Collection[int]) -> Iterator[pd.DataFrame]:\n",
    "        # Iterate over all folds\n",
    "        for fold in folds:\n",
    "            # Iterate over all subjects in the fold\n",
    "            for subj in self._folds[fold]:       # Anna: subj in fold?\n",
    "                subj_data = self._data[self._data[\"subj\"] == subj]\n",
    "                # Iterate over all sentences this subject read\n",
    "                for sn in subj_data[\"sn\"].unique():\n",
    "                    trial_data = subj_data[subj_data[\"sn\"] == sn]\n",
    "                    yield trial_data\n",
    "                    \n",
    "                    \n",
    "    def iter_folds(\n",
    "        self, folds: Collection[int]) -> Iterator[Tuple[torch.Tensor, torch.Tensor, int]]:\n",
    "        for trial_data in self._iter_trials(folds):\n",
    "            predictors = trial_data[self._features].to_numpy()\n",
    "            #predictors = np.reshape(predictors, (int(len(predictors)/278), 278, predictors.shape[1]))\n",
    "            label = trial_data[\"group\"].unique().item()\n",
    "            subj = trial_data[\"subj\"].unique().item()\n",
    "            reading_speed = trial_data[\"reading_speed\"].unique().item()\n",
    "            #  X = (time_steps, features)\n",
    "            X = predictors\n",
    "            y = torch.tensor(label, dtype=torch.float)\n",
    "            rs = torch.tensor(reading_speed , dtype=torch.float)\n",
    "            yield X, y, subj, rs\n",
    "                    \n",
    "\n",
    "    @property\n",
    "    def num_features(self) -> int:\n",
    "        \"\"\"Number of features per word (excluding word vector dimensions).\"\"\"\n",
    "        return len(self._features)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def max_number_of_sentences(self):\n",
    "        data_copy = self._data.copy()\n",
    "        max_s_count = data_copy.groupby(by=\"subj\").sn.unique()\n",
    "        return max([len(x) for x in max_s_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c918bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprocessor: EyetrackingDataPreprocessor,\n",
    "       # word_vector_model: WordVectorModel,\n",
    "        folds: Collection[int],\n",
    "        batch_subjects: bool = False,\n",
    "    ):\n",
    "        self.sentences = list(preprocessor.iter_folds(folds))\n",
    "        self._subjects = list(np.unique([subj for _, _, subj, _ in self.sentences]))\n",
    "        self.num_features = preprocessor.num_features# + word_vector_model.dimensions()\n",
    "        self.batch_subjects = batch_subjects\n",
    "        #self.max_sentence_length = preprocessor.max_sentence_length\n",
    "        self.max_number_of_sentences = preprocessor.max_number_of_sentences\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        if self.batch_subjects:\n",
    "            subject = self._subjects[index]\n",
    "            subject_sentences = [\n",
    "                (X, y, subj, rs) for X, y, subj, rs in self.sentences if subj == subject\n",
    "            ]\n",
    "            X = torch.stack([torch.FloatTensor(X) for X, _, _, _ in subject_sentences]) #[X for X, _, _ in subject_sentences] #torch.FloatTensor([X for X, _, _ in subject_sentences])\n",
    "            y = torch.stack([y for _, y, _, _ in subject_sentences]).unique().squeeze() \n",
    "            rs = torch.stack([rs for _, _, _, rs in subject_sentences]).unique().squeeze()\n",
    "            return X, y, subject, rs\n",
    "\n",
    "        else:\n",
    "            X, y, subj, rs = self.sentences[index]\n",
    "            #X = torch.from_numpy(X).float()   \n",
    "            return X, y, subj, rs\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.batch_subjects:\n",
    "            return len(self._subjects)\n",
    "        else:\n",
    "            return len(self.sentences)\n",
    "\n",
    "    def standardize(self, mean: torch.Tensor, sd: torch.Tensor):\n",
    "        self.sentences = [\n",
    "            (apply_standardization(X, mean, sd), y, subj, rs)\n",
    "            for X, y, subj, rs in self.sentences\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f129fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):  \n",
    "    def __init__(self,\n",
    "                dim_upscale = int,\n",
    "                inner_dim_upscale = int,\n",
    "                num_heads = int, \n",
    "                num_layers = int, \n",
    "                dropout = 0\n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.dim_upscale = dim_upscale\n",
    "        self.inner_dim_upscale = inner_dim_upscale\n",
    "        \n",
    "        # layer norm for multi-head attention\n",
    "        self.attn_layer_norm = nn.LayerNorm(self.dim_upscale)\n",
    "        # layer norm for feedforward network\n",
    "        self.ffn_layer_norm = nn.LayerNorm(self.dim_upscale)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim = self.dim_upscale,  \n",
    "                                                 num_heads = self.num_heads, \n",
    "                                                 bias = True,\n",
    "                                                 batch_first = True)\n",
    "        # feed forward\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(self.dim_upscale, self.inner_dim_upscale, bias = True),\n",
    "            nn.LayerNorm(self.inner_dim_upscale),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.inner_dim_upscale, self.dim_upscale, bias = True)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "        # pass embeddings through multi-head attention\n",
    "        x, attn_probs = self.attention(src, src, src, src_mask)\n",
    "\n",
    "        # residual add and norm\n",
    "        first_out = self.attn_layer_norm(x + src)\n",
    "\n",
    "        # position-wise feed-forward network\n",
    "        x2 = self.ff(first_out)\n",
    "\n",
    "        # residual add and norm\n",
    "        second_out = self.ffn_layer_norm(x2 + first_out)  # first_out + x2\n",
    "\n",
    "        return second_out, attn_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4390ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                dim_upscale = int,\n",
    "                inner_dim_upscale = int,\n",
    "                num_heads = int, \n",
    "                num_layers = int, \n",
    "                dropout = 0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.dim_upscale = dim_upscale\n",
    "        self.inner_dim_upscale = inner_dim_upscale\n",
    "        \n",
    "        # create n_layers encoders \n",
    "        self.layers = nn.ModuleList([EncoderLayer(\n",
    "                                    dim_upscale = self.dim_upscale,\n",
    "                                    num_heads = self.num_heads, \n",
    "                                    inner_dim_upscale = self.inner_dim_upscale,\n",
    "                                    dropout = self.dropout)\n",
    "                                     for layer in range(self.num_layers)])\n",
    "\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "\n",
    "        # pass the sequences through each encoder\n",
    "        for layer in self.layers:\n",
    "            src, attn_probs = layer(src, src_mask)\n",
    "\n",
    "        self.attn_probs = attn_probs\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40b0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annas changes\n",
    "class TransformerWithCustomPositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embed_dim = 30,\n",
    "        d_model = 14,\n",
    "        dim_upscale = 128,\n",
    "        inner_dim_upscale = 4*128,\n",
    "        num_heads = 1, \n",
    "        num_layers = 1, \n",
    "        dropout = 0,\n",
    "        mask_prob = 0.2,\n",
    "        replace_prob = 0, # 0.9\n",
    "        mask_token_id = 2,\n",
    "        pad_token_id = -5,\n",
    "        mask_ignore_token_ids = []\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.d_model = d_model\n",
    "        self.mask_prob = mask_prob\n",
    "        self.replace_prob = replace_prob\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.dim_upscale = dim_upscale\n",
    "        self.inner_dim_upscale = inner_dim_upscale\n",
    "\n",
    "        # token ids\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.mask_ignore_token_ids = set([*mask_ignore_token_ids, self.pad_token_id])\n",
    "        \n",
    "        self.positional_encoding = AnnasPositionalEncoding(fixations = self.embed_dim, \n",
    "                                                           features = self.d_model)\n",
    "        \n",
    "        self.upscale = nn.Linear(self.d_model, self.dim_upscale, bias = True)\n",
    "        self.downscale = nn.Linear(self.dim_upscale, self.d_model, bias = True)\n",
    "        \n",
    "        self.encoder = Encoder(dim_upscale = self.dim_upscale, \n",
    "                               num_heads = self.num_heads, \n",
    "                               num_layers = self.num_layers,\n",
    "                               inner_dim_upscale = self.inner_dim_upscale, \n",
    "                               dropout = self.dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # TransformerEncoder\n",
    "    def forward(self, seq, identity = False):\n",
    "        # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "        # also do not include these special tokens in the tokens chosen at random\n",
    "        no_mask = mask_with_tokens_3D(seq, self.mask_ignore_token_ids) \n",
    "        mask = get_mask_subset_with_prob_3D(~no_mask, self.mask_prob)\n",
    "        hidden = no_mask + mask # all elements that the model will not attend to\n",
    "\n",
    "        # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
    "        masked_seq = seq.clone().detach().to(device)\n",
    "        \n",
    "        #   Static positional encoding\n",
    "        masked_seq_pos = self.positional_encoding(masked_seq, mask = None) #for hidden fixations ~ no_mask\n",
    "\n",
    "        #[mask] input = This does not change the input if replace_prob = 0\n",
    "        # masked_replace_prob = prob_mask_like_3D(seq, self.replace_prob) # Anna: select 90% of all values  (ignore all masking for now)\n",
    "        # masked_seq = masked_seq_pos.masked_fill(mask * masked_replace_prob, self.mask_token_id) # Anna: select 90% only of those selected for masking\n",
    "        \n",
    "        # derive labels to predict\n",
    "        labels = seq.masked_fill(~mask, self.pad_token_id)\n",
    "        \n",
    "        #import pdb; \n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        if identity:\n",
    "            attn_mask = no_mask[:,:,0]\n",
    "        else:\n",
    "            attn_mask = hidden[:,:,0]\n",
    "        \n",
    "        # Upscaling\n",
    "        masked_seq_upscaled = self.upscale(masked_seq_pos)\n",
    "       # labels_upscaled = self.upscale(seq)\n",
    "       # mask_upscaled = mask[:,:,0].unsqueeze(2).expand(64, 30, 128)\n",
    "       # labels_upscaled = labels_upscaled.masked_fill(~mask_upscaled, self.pad_token_id)\n",
    "        \n",
    "        # Encoder\n",
    "        out = self.encoder(masked_seq_upscaled, \n",
    "                           attn_mask)  \n",
    "        out = self.downscale(out)\n",
    "\n",
    "        return out, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c30ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "test_fold = 2\n",
    "dev_fold = 3\n",
    "train_folds = [\n",
    "                fold\n",
    "                for fold in range(NUM_FOLDS)\n",
    "                if fold != test_fold and fold != dev_fold\n",
    "            ]\n",
    "\n",
    "preprocessor = EyetrackingDataPreprocessor(\n",
    "    csv_file = file, \n",
    "   num_folds = NUM_FOLDS\n",
    ")\n",
    "\n",
    "train_dataset = EyetrackingDataset(\n",
    "                preprocessor,\n",
    "                folds=train_folds,\n",
    "                batch_subjects=BATCH_SUBJECTS,\n",
    "            )\n",
    "mean, sd = getmeansd(train_dataset, batch=BATCH_SUBJECTS)\n",
    "train_dataset.standardize(mean, sd)\n",
    "\n",
    "dev_dataset = EyetrackingDataset(\n",
    "    preprocessor,\n",
    "    folds=[dev_fold],\n",
    "    batch_subjects=BATCH_SUBJECTS,\n",
    ")\n",
    "dev_dataset.standardize(mean, sd)\n",
    "\n",
    "test_dataset = EyetrackingDataset(\n",
    "    preprocessor,\n",
    "    folds=[test_fold],\n",
    "    batch_subjects=BATCH_SUBJECTS,\n",
    ")\n",
    "test_dataset.standardize(mean, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb3021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 done. Loss: 0.0414509875207982\n",
      "Epoch 1 done. Loss: 0.005692043323660086\n",
      "Epoch 2 done. Loss: 0.005565003407086102\n",
      "Epoch 3 done. Loss: 0.0026908729436092445\n",
      "Epoch 4 done. Loss: 0.0021667877080174766\n",
      "Epoch 5 done. Loss: 0.0018108091476983325\n",
      "Epoch 6 done. Loss: 0.0012899188592892246\n",
      "Epoch 7 done. Loss: 0.00105100241335991\n",
      "Epoch 8 done. Loss: 0.0027093871698090086\n",
      "Epoch 9 done. Loss: 0.0007505658102954712\n",
      "Epoch 10 done. Loss: 0.0006718648890480989\n",
      "Epoch 11 done. Loss: 0.0019070828856853604\n",
      "Epoch 12 done. Loss: 0.0016997671171364499\n",
      "Epoch 13 done. Loss: 0.00048469220651690785\n",
      "Epoch 14 done. Loss: 0.001706456957474305\n",
      "Epoch 15 done. Loss: 0.0004046807703225952\n",
      "Epoch 16 done. Loss: 0.0014526391673761808\n",
      "Epoch 17 done. Loss: 0.0003322193759129117\n",
      "Epoch 18 done. Loss: 0.00039245590450661094\n",
      "Epoch 19 done. Loss: 0.00023888126498335829\n",
      "Epoch 20 done. Loss: 0.00028911324174464743\n",
      "Epoch 21 done. Loss: 0.000323692189058548\n",
      "Epoch 22 done. Loss: 0.0002517591784312636\n",
      "Epoch 23 done. Loss: 0.00030047684384966564\n",
      "Epoch 24 done. Loss: 0.001466567403914384\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle = True)\n",
    "\n",
    "trainer = TransformerWithCustomPositionalEncoding(embed_dim = 30,\n",
    "                                                  num_heads = 64, \n",
    "                                                  d_model = NUM_FEATURES,\n",
    "                                                  num_layers = 1,\n",
    "                                                  dropout = 0.1,\n",
    "                                                  dim_upscale = 128).to(device)\n",
    "\n",
    "# # Setup optimizer to optimize model's parameters\n",
    "optimizer = Adam(trainer.parameters(), lr=1e-3)\n",
    "patience = 10\n",
    "\n",
    "epochs = 201\n",
    "min_epochs = 15\n",
    "best_losses = [float(\"inf\")] * patience\n",
    "\n",
    "epoch_count = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_count += 1\n",
    "    epoch_loss = 0.0\n",
    "    train_loss = 0\n",
    "    trainer.train()\n",
    "    ### Training\n",
    "    for X, _, _, _ in train_loader:\n",
    "\n",
    "        # 1. Forward pass \n",
    "        X = X.to(device)\n",
    "        train_preds, labels, mask = trainer(X, identity = False)\n",
    "            \n",
    "        # 2. Calculate loss/accuracy\n",
    "        loss = mse_loss(\n",
    "            labels,\n",
    "            train_preds,\n",
    "            mask\n",
    "        )\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss = epoch_loss/math.ceil(len(train_loader.dataset)/BATCH_SIZE)\n",
    "    print(f\"Epoch {epoch} done. Loss: {train_loss}\")\n",
    "\n",
    "    if dev_dataset is not None:\n",
    "        trainer.eval()\n",
    "        dev_loss = 0\n",
    "        dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
    "        for X_dev, _, _, _ in dev_loader:\n",
    "            X_dev = X_dev.to(device)\n",
    "            dev_preds, labels, mask = trainer(X_dev, identity = False)\n",
    "            dloss = mse_loss(\n",
    "                labels,\n",
    "                dev_preds,\n",
    "                mask\n",
    "            )\n",
    "            dev_loss += dloss.item() \n",
    "        eval_loss = dev_loss /math.ceil(len(dev_loader.dataset)/BATCH_SIZE)   \n",
    "        trainer.train()\n",
    "        if epoch > min_epochs and all(eval_loss > i for i in best_losses):\n",
    "            epoch_count -= patience - best_losses.index(min(best_losses))\n",
    "            break\n",
    "        else:\n",
    "            best_losses.pop(0)\n",
    "            best_losses.append(eval_loss)\n",
    "\n",
    "#torch.save(trainer.state_dict(), CHECKPOINT_PATH)\n",
    "\n",
    "torch.save({'epoch': epoch_count,\n",
    "            'model_state_dict': trainer.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            'dev_loss': min(best_losses)\n",
    "            }, CHECKPOINT_PATH + \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c7304",
   "metadata": {},
   "source": [
    "Save the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be044f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer, CHECKPOINT_PATH+\"trainer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029681f3",
   "metadata": {},
   "source": [
    "### Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e2cc99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerWithCustomPositionalEncoding(\n",
       "  (positional_encoding): AnnasPositionalEncoding()\n",
       "  (upscale): Linear(in_features=14, out_features=128, bias=True)\n",
       "  (downscale): Linear(in_features=128, out_features=14, bias=True)\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerWithCustomPositionalEncoding(embed_dim = 30,\n",
    "                                                  num_heads = 64, \n",
    "                                                  d_model = NUM_FEATURES,\n",
    "                                                  num_layers = 1,\n",
    "                                                  dropout = 0.1,\n",
    "                                                  dim_upscale = 128).to(device)\n",
    "optimizer = Adam(trainer.parameters(), lr=1e-3)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH+\"model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39983ca1",
   "metadata": {},
   "source": [
    "#### Loss is way too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb5dbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3453269522441061"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
    "dev_loss = 0\n",
    "\n",
    "for X_dev, _, _, _ in dev_loader:\n",
    "    X_dev = X_dev.to(device)\n",
    "    dev_preds, labels, mask = model(X_dev, identity = False)\n",
    "    dloss = mse_loss(\n",
    "        labels,\n",
    "        dev_preds,\n",
    "        mask\n",
    "    )\n",
    "    dev_loss += dloss.item() \n",
    "    \n",
    "eval_loss = dev_loss /math.ceil(len(dev_loader.dataset)/BATCH_SIZE)   \n",
    "eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c56eb0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3445869858066241"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_loss = 0\n",
    "\n",
    "for X_test, _, _, _ in test_loader:\n",
    "    X_test = X_test.to(device)\n",
    "    test_preds, labels, mask = model(X_test, identity = False)\n",
    "    tloss = mse_loss(\n",
    "        labels,\n",
    "        test_preds,\n",
    "        mask\n",
    "    )\n",
    "    test_loss += tloss.item() \n",
    "\n",
    "test_loss = test_loss /math.ceil(len(test_loader.dataset)/BATCH_SIZE)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f482c9b",
   "metadata": {},
   "source": [
    "#### If I use the trained model (not load the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56f5769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007113359695520356"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = 0\n",
    "for X_test, _, _, _ in test_loader:\n",
    "    X_test = X_test.to(device)\n",
    "    test_preds, labels, mask = trainer(X_test, identity = False)\n",
    "    tloss = mse_loss(\n",
    "        labels,\n",
    "        test_preds,\n",
    "        mask\n",
    "    )\n",
    "    test_loss += tloss.item() \n",
    "\n",
    "test_loss = test_loss /math.ceil(len(test_loader.dataset)/BATCH_SIZE)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4d7e2",
   "metadata": {},
   "source": [
    "### Alternative (loading the whole model, not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb8e553c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007811346691192335"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(CHECKPOINT_PATH+\"trainer.pth\")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_loss = 0\n",
    "\n",
    "for X_test, _, _, _ in test_loader:\n",
    "    X_test = X_test.to(device)\n",
    "    test_preds, labels, mask = model(X_test, identity = False)\n",
    "    tloss = mse_loss(\n",
    "        labels,\n",
    "        test_preds,\n",
    "        mask\n",
    "    )\n",
    "    test_loss += tloss.item() \n",
    "\n",
    "test_loss = test_loss /math.ceil(len(test_loader.dataset)/BATCH_SIZE)\n",
    "test_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

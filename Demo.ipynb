{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444f024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 14:46:49.885277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-19 14:46:49.954202: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-19 14:46:49.971768: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "#from IPython.display import set_matplotlib_formats\n",
    "#matplotlib_inline.backend_inline.set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "# ## tqdm for loading bars\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# for one-hot encoding\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from mlm_pytorch import MLM\n",
    "\n",
    "# Transformer wrapper\n",
    "import tensorflow as tf\n",
    "from x_transformers import TransformerWrapper, Encoder\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Positional encoding in two dimensions\n",
    "from positional_encodings.torch_encodings import PositionalEncodingPermute1D, PositionalEncoding1D\n",
    "\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/simple_transformer\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e66f8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.5\n",
    "    import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21cf40",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91aec7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "NUM_FEATURES = 1\n",
    "NUM_FIX = 30 \n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 31\n",
    "\n",
    "\n",
    "num_fix = NUM_FIX\n",
    "num_features = NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8823925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def mse_loss(target, input, mask):\n",
    "    out = (input[mask]-target[mask])**2\n",
    "    return out.mean()\n",
    "\n",
    "def mask_with_tokens_3D(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    reduced = torch.any(mask, dim=-1, keepdim=True)\n",
    "    expanded = reduced.expand_as(mask)\n",
    "    return expanded\n",
    "\n",
    "def get_mask_subset_with_prob_3D(mask, prob):\n",
    "    batch, num_fix, num_features, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * num_fix)\n",
    "\n",
    "    num_tokens = mask.sum(dim=-2, keepdim=True)\n",
    "    mask_excess = (mask.cumsum(dim=-2)[:,:,0] > (num_tokens[:,:,0] * prob).ceil())\n",
    "    mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "    rand = torch.rand((batch, num_fix, num_features), device=device).masked_fill(~mask, -1e9)\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-2)\n",
    "    sampled_indices = (sampled_indices[:,:,0] + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "    new_mask = torch.zeros((batch, num_fix + 1), device=device)\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)\n",
    "    new_mask = new_mask[:, 1:].bool()\n",
    "    \n",
    "    return new_mask.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "\n",
    "def prob_mask_like_3D(t, prob):\n",
    "    temp = torch.zeros_like(t[:,:,0]).float().uniform_(0, 1) < prob\n",
    "    return temp.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "    \n",
    "def pad_group_with_zeros(group, target_rows):\n",
    "    # Calculate the number of rows to add\n",
    "    num_missing_rows = target_rows - len(group)\n",
    "    if num_missing_rows > 0:\n",
    "        # Create a DataFrame with the required number of padding rows\n",
    "        # input padding\n",
    "        zero_rows = pd.DataFrame(0.3333, index=range(num_missing_rows), columns=group.columns)\n",
    "        # Label padding\n",
    "        # zero_rows.iloc[:, 0] = 31\n",
    "        # Concatenate the group with the zero rows\n",
    "        group = pd.concat([group, zero_rows], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert Series in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        trial, label = sample['trial'], sample['label']\n",
    "        trial = torch.from_numpy(trial).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "        return trial, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5178796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPositionalEncoding(nn.Module):\n",
    "    \"\"\"Learnable positional encoding for both features and fixations\n",
    "    Assumes input `x` is of shape [batch_size, fixations, embed_dim]\"\"\"\n",
    "    def __init__(self, fixations, embed_dim, max_len= num_features):\n",
    "        super(CustomPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix\n",
    "        self.encoding = nn.Parameter(torch.zeros(fixations, max_len)).to(device)\n",
    "        nn.init.xavier_uniform_(self.encoding)  # Xavier initialization for better training stability\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_encoding = self.encoding  * mask\n",
    "         \n",
    "        return x + pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3b7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len, l2norm_embed = False):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5 if not l2norm_embed else 1.\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.l2norm_embed = l2norm_embed\n",
    "        self.emb = nn.Embedding(max_seq_len, dim)\n",
    "\n",
    "    def forward(self, x, pos = None, seq_start_pos = None, mask = None):\n",
    "        seq_len, device = x.shape[1], x.device\n",
    "        assert seq_len <= self.max_seq_len, f'you are passing in a sequence length of {seq_len} but your absolute positional embedding has a max sequence length of {self.max_seq_len}'\n",
    "\n",
    "        #if not exists(pos):\n",
    "        pos = torch.arange(seq_len, device = device)\n",
    "\n",
    "        #if exists(seq_start_pos):\n",
    "        #    pos = (pos - seq_start_pos[..., None]).clamp(min = 0)\n",
    "\n",
    "        pos_emb = self.emb(pos)\n",
    "        pos_emb = pos_emb * self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_emb = pos_emb * mask\n",
    "            \n",
    "        return l2norm(pos_emb) if self.l2norm_embed else pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=num_fix):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model%2 != 0:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)[:,0:-1]\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to(device)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        pos_enc = self.pe[:, :x.size(1)]*mask\n",
    "        return x + pos_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899748c",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e747c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSCFixationsOrder(Dataset):\n",
    "    \"\"\"Dataset with the long-format sequence of fixations made during reading by dyslexic \n",
    "    and normally-developing Russian-speaking monolingual children.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None, target_transform = None, \n",
    "                 n_fix = NUM_FIX, \n",
    "                 dropPhonologyFeatures = True, dropPhonologySubjects = True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on a label.\n",
    "        \"\"\"\n",
    "        self.fixations_frame = pd.read_csv(csv_file)\n",
    "        \n",
    "        # remove demography and identification\n",
    "        self.fixations_frame = self.fixations_frame.drop(columns = ['fix_x', \n",
    "                                                                    'fix_y', 'full_text' \n",
    "                                                                    ]) \n",
    "        \n",
    "        #self.fixations_frame = self.fixations_frame[order_cols]\n",
    "        \n",
    "        # Log-transforming appropriate measures\n",
    "        to_transform = ['frequency', 'fix_dur'] \n",
    "        for column in to_transform:\n",
    "            self.fixations_frame[column] = self.fixations_frame[column].apply(lambda x: np.log(x) if x > 0 else 0) \n",
    "\n",
    "        # Center \n",
    "        cols = ['fix_dur', 'landing', 'predictability',\n",
    "                'frequency', 'word_length', 'number.morphemes', \n",
    "                'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                'sac_vel']\n",
    "        for col in cols:\n",
    "            self.fixations_frame[col] = np.where(self.fixations_frame[col] == 0, -4,\n",
    "                (self.fixations_frame[col] - self.fixations_frame[col].mean())/self.fixations_frame[col].std(ddof=0)) \n",
    "        \n",
    "\n",
    "        # Drop padding \n",
    "        self.fixations_frame = self.fixations_frame[self.fixations_frame['fix_dur'] != -4]\n",
    "        \n",
    "        \n",
    "        # Convert direction to a dummy-coded variable\n",
    "        self.fixations_frame['direction'] = np.where(self.fixations_frame['direction'].isnull(), 0,\n",
    "                                                     self.fixations_frame['direction'])\n",
    "        self.fixations_frame = pd.concat([self.fixations_frame, \n",
    "                                          pd.get_dummies(self.fixations_frame['direction'], \n",
    "                                                         prefix='dummy')], axis=1)\n",
    "\n",
    "        if dropPhonologySubjects == True:\n",
    "            # Drop subjects\n",
    "            self.fixations_frame.dropna(axis = 0, how = 'any', inplace = True)\n",
    "        else:\n",
    "            # Drop columns\n",
    "            self.fixations_frame.dropna(axis = 1, how = 'any', inplace = True)\n",
    "        \n",
    "        \n",
    "        self.fixations_frame['subj'] = self.fixations_frame['subj'].astype(str)\n",
    "        self.fixations_frame['item'] = self.fixations_frame['sn'].astype(str)\n",
    "        self.fixations_frame['Combined'] = self.fixations_frame[['subj', 'item']].agg('_'.join, axis=1)\n",
    "        \n",
    "        # cleaning up\n",
    "        self.fixations_frame.drop(columns = ['subj', 'item', 'direction', 'dummy_0', 'sn',\\\n",
    "                                            'dummy_DOWN', 'dummy_LEFT', 'dummy_UP'\\\n",
    "                                            ], inplace = True)\n",
    "        self.fixations_frame.drop(columns = ['word_length', 'predictability', \n",
    "                                             'frequency', 'number.morphemes', 'fix_index'], \n",
    "                                             inplace = True)\n",
    "        \n",
    "        # Leaving just one feature for now\n",
    "        self.fixations_frame.drop(columns = ['landing', \n",
    "                'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                'sac_vel', 'dummy_RIGHT'], inplace = True)\n",
    "        \n",
    "\n",
    "        padded = self.fixations_frame.groupby('Combined', group_keys=False).apply(lambda x: \n",
    "                                                                           pad_group_with_zeros(x, n_fix))\n",
    "        padded.drop(columns = \"Combined\", inplace = True)\n",
    "    \n",
    "        \n",
    "        #### Fixation index is the label\n",
    "        self.fixations_frame = padded.to_numpy()\n",
    "        dataReshaped = np.reshape(self.fixations_frame, (int(len(self.fixations_frame)/n_fix), \n",
    "                                                         n_fix, self.fixations_frame.shape[1]))\n",
    "\n",
    "        self.predictors = dataReshaped[:,:,1:]\n",
    "        self.labels = dataReshaped[:,:,0]\n",
    "        self.labels = to_categorical(self.labels-1, num_classes=NUM_CLASSES)   # one-hot encoding\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        trial = self.predictors[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        sample = {'trial': trial, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            sample = self.target_transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8466dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = RSCFixationsOrder(csv_file='data/RSC_long_no_word_padded_word_pos.csv', \n",
    "                                    transform=ToTensor(),\n",
    "                                    dropPhonologySubjects = True)\n",
    "\n",
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "val_size = int(0.1 * len(transformed_dataset))\n",
    "test_size = len(transformed_dataset) - val_size - train_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511ba45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 30, 1])\n"
     ]
    }
   ],
   "source": [
    "trials, labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {trials.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa35291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.1000],\n",
       "        [0.2000],\n",
       "        [0.1000],\n",
       "        [0.3000],\n",
       "        [0.5000],\n",
       "        [0.5000],\n",
       "        [0.6000],\n",
       "        [0.7000],\n",
       "        [0.9000],\n",
       "        [0.8000],\n",
       "        [0.3333],\n",
       "        [0.3333],\n",
       "        [0.3333],\n",
       "        [0.3333]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[1, 0:15,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508254d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabe87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annas changes\n",
    "class TransformerWithCustomPositionalEncoding2D(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embed_dim, \n",
    "        num_heads, \n",
    "        num_layers, \n",
    "        max_len=5000,\n",
    "        mask_prob = 0.15,\n",
    "        replace_prob = 1, # 0.9\n",
    "        mask_token_id = 2,\n",
    "        pad_token_id = 0.3333,\n",
    "        mask_ignore_token_ids = []\n",
    "        ):\n",
    "        super(TransformerWithCustomPositionalEncoding2D, self).__init__()\n",
    "        \n",
    "        self.mask_prob = mask_prob\n",
    "        self.replace_prob = replace_prob\n",
    "\n",
    "        # token ids\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(num_features)\n",
    "        \n",
    "        # transformer\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, \n",
    "                                                        nhead=num_heads, \n",
    "                                                        batch_first = True)\n",
    "        self.transformer = TransformerEncoder(self.encoder_layer, num_layers=num_layers).to(device)\n",
    "\n",
    "    def forward(self, seq, before):\n",
    "        # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "        # also do not include these special tokens in the tokens chosen at random\n",
    "        no_mask = mask_with_tokens_3D(seq, self.mask_ignore_token_ids) \n",
    "        mask = get_mask_subset_with_prob_3D(~no_mask, self.mask_prob)\n",
    "\n",
    "        # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
    "        masked_seq = seq.clone().detach()\n",
    "        \n",
    "        #   Static positional encoding\n",
    "        masked_seq_pos = self.positional_encoding(masked_seq, mask = ~no_mask)\n",
    "\n",
    "        # [mask] input\n",
    "        masked_replace_prob = prob_mask_like_3D(seq, self.replace_prob) # Anna: select 90% of all values  (ignore all masking for now)\n",
    "        masked_seq = masked_seq_pos.masked_fill(mask * masked_replace_prob, self.mask_token_id) # Anna: select 90% only of those selected for masking\n",
    "        \n",
    "        # derive labels to predict\n",
    "        labels = seq.masked_fill(~mask, self.pad_token_id).squeeze(2)\n",
    "        \n",
    "        # Pass through the transformer\n",
    "        if before:\n",
    "            preds = self.transformer(masked_seq.squeeze(2))\n",
    "        else:\n",
    "            preds = self.transformer(masked_seq).squeeze(2)\n",
    "            \n",
    "        \n",
    "        my_loss = mse_loss(\n",
    "            labels,\n",
    "            preds,\n",
    "            mask = mask.squeeze(2)\n",
    "        )\n",
    "\n",
    "        return preds, my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fb3021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Flattening the input before feeding it to the transformer = True\n",
      "Epoch 1: Train Loss: 0.1368, Test Loss: 0.0483\n",
      "Epoch 11: Train Loss: 0.0276, Test Loss: 0.0265\n",
      "Epoch 21: Train Loss: 0.0236, Test Loss: 0.0233\n",
      "Epoch 31: Train Loss: 0.0217, Test Loss: 0.0220\n",
      "Input:  tensor([[0.1111],\n",
      "        [0.1111],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.4444],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.7778],\n",
      "        [0.7778],\n",
      "        [0.7778],\n",
      "        [0.7778],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.3333]], device='cuda:0')\n",
      "Predictions:  tensor([-0.0195,  0.0576,  0.0978,  0.2506, -2.1445, -0.4618,  0.3668,  0.6642,\n",
      "         0.7162,  0.8439,  0.6074,  0.5196,  0.5091,  0.5393,  0.4169],\n",
      "       device='cuda:0')\n",
      "\n",
      " Flattening the input before feeding it to the transformer = False\n",
      "Epoch 1: Train Loss: 0.2418, Test Loss: 0.2227\n",
      "Epoch 11: Train Loss: 0.0853, Test Loss: 0.0863\n",
      "Epoch 21: Train Loss: 0.0837, Test Loss: 0.0849\n",
      "Epoch 31: Train Loss: 0.0838, Test Loss: 0.0846\n",
      "Input:  tensor([[0.1000],\n",
      "        [0.2000],\n",
      "        [0.3000],\n",
      "        [0.4000],\n",
      "        [0.5000],\n",
      "        [0.7000],\n",
      "        [0.8000],\n",
      "        [0.9000],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333]], device='cuda:0')\n",
      "Predictions:  tensor([0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283,\n",
      "        0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# flattening input before feeding it to transformer (vs. after)\n",
    "settings = [True, False]\n",
    "\n",
    "for before in settings:\n",
    "    print(\"\\n\",\n",
    "          \"Flattening the input before feeding it to the transformer =\", before)\n",
    "    if before:\n",
    "        embed_dim = num_fix\n",
    "    else:\n",
    "        embed_dim = num_features\n",
    "\n",
    "    trainer = TransformerWithCustomPositionalEncoding2D(num_heads = 1, \n",
    "                                                        num_layers= 2, \n",
    "                                                        embed_dim = embed_dim).cuda()\n",
    "\n",
    "    # # Setup optimizer to optimize model's parameters\n",
    "    optimizer = Adam(trainer.parameters(), lr=3e-4)\n",
    "\n",
    "    epochs = 31\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        ### Training\n",
    "        trainer.train()\n",
    "\n",
    "        for X_train, y_train in train_loader:\n",
    "            # 1. Forward pass \n",
    "            # 2. Calculate loss/accuracy\n",
    "            train_preds, loss = trainer(X_train, before = before)\n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 4. Loss backwards\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X_train.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        #### Evaluation\n",
    "        test_loss = 0.0\n",
    "        trainer.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in test_loader:\n",
    "                test_preds, tloss = trainer(X_test, before = before)\n",
    "                test_loss += tloss.item() * X_test.size(0)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "        # Print out what's happening every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    print('Input: ', X_test[1, 0:15])\n",
    "    print('Predictions: ', test_preds[1, 0:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

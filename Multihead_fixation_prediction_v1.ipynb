{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444f024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 13:41:37.526024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-05 13:41:37.591949: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-05 13:41:37.610718: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "#from IPython.display import set_matplotlib_formats\n",
    "#matplotlib_inline.backend_inline.set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "# ## tqdm for loading bars\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# for one-hot encoding\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "from typing import TextIO, Callable, Collection, Dict, Iterator, List, Tuple, Type, TypeVar\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "# Transformer wrapper\n",
    "import tensorflow as tf\n",
    "from x_transformers import TransformerWrapper, Encoder\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Positional encoding in two dimensions\n",
    "from positional_encodings.torch_encodings import PositionalEncodingPermute1D, PositionalEncoding1D\n",
    "\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/simple_transformer\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21cf40",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91aec7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "NUM_FEATURES = 14\n",
    "NUM_FIX = 30 \n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 31\n",
    "BATCH_SUBJECTS = False\n",
    "\n",
    "num_fix = NUM_FIX\n",
    "num_features = NUM_FEATURES\n",
    "ablation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8823925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def mse_loss(target, input, mask):\n",
    "    out = (input[mask]-target[mask])**2\n",
    "    return out.mean()\n",
    "\n",
    "def mask_with_tokens_3D(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    reduced = torch.any(mask, dim=-1, keepdim=True)\n",
    "    expanded = reduced.expand_as(mask)\n",
    "    return expanded\n",
    "\n",
    "def get_mask_subset_with_prob_3D(mask, prob):\n",
    "    batch, num_fix, num_features, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * num_fix)\n",
    "\n",
    "    num_tokens = mask.sum(dim=-2, keepdim=True)\n",
    "    mask_excess = (mask.cumsum(dim=-2)[:,:,0] > (num_tokens[:,:,0] * prob).ceil())\n",
    "    mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "    rand = torch.rand((batch, num_fix, num_features), device=device).masked_fill(~mask, -1e9)\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-2)\n",
    "    sampled_indices = (sampled_indices[:,:,0] + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "    new_mask = torch.zeros((batch, num_fix + 1), device=device)\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)\n",
    "    new_mask = new_mask[:, 1:].bool()\n",
    "    \n",
    "    return new_mask.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "\n",
    "def prob_mask_like_3D(t, prob):\n",
    "    temp = torch.zeros_like(t[:,:,0]).float().uniform_(0, 1) < prob\n",
    "    return temp.unsqueeze_(2).expand(-1,-1, num_features)\n",
    "    \n",
    "    \n",
    "def pad_group_with_zeros(group, target_rows):\n",
    "    # Calculate the number of rows to add\n",
    "    num_missing_rows = target_rows - len(group)\n",
    "    if num_missing_rows > 0:\n",
    "        # Create a DataFrame with the required number of padding rows\n",
    "        # input padding\n",
    "        zero_rows = pd.DataFrame(0.3333, index=range(num_missing_rows), columns=group.columns)\n",
    "        # Label padding\n",
    "        # zero_rows.iloc[:, 0] = 31\n",
    "        # Concatenate the group with the zero rows\n",
    "        group = pd.concat([group, zero_rows], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert Series in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        trial, label = sample['trial'], sample['label']\n",
    "        trial = torch.from_numpy(trial).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "        return trial, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5178796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPositionalEncoding(nn.Module):\n",
    "    \"\"\"Learnable positional encoding for both features and fixations\n",
    "    Assumes input `x` is of shape [batch_size, fixations, embed_dim]\"\"\"\n",
    "    def __init__(self, fixations = 30, features = None):\n",
    "        super(CustomPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Initialize a learnable positional encoding matrix\n",
    "        self.encoding = nn.Parameter(torch.zeros(fixations, features)).to(device)\n",
    "        nn.init.xavier_uniform_(self.encoding)  # Xavier initialization for better training stability\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_encoding = self.encoding  * mask\n",
    "        else:\n",
    "            pos_encoding = self.encoding\n",
    "        return x + pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3b7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=278, l2norm_embed = False):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5 if not l2norm_embed else 1.\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.l2norm_embed = l2norm_embed\n",
    "        self.emb = nn.Embedding(max_seq_len, dim)\n",
    "\n",
    "    def forward(self, x, pos = None, seq_start_pos = None, mask = None):\n",
    "        seq_len, device = x.shape[1], x.device\n",
    "        assert seq_len <= self.max_seq_len, f'you are passing in a sequence length of {seq_len} but your absolute positional embedding has a max sequence length of {self.max_seq_len}'\n",
    "\n",
    "        #if not exists(pos):\n",
    "        pos = torch.arange(seq_len, device = device)\n",
    "\n",
    "        #if exists(seq_start_pos):\n",
    "        #    pos = (pos - seq_start_pos[..., None]).clamp(min = 0)\n",
    "\n",
    "        pos_emb = self.emb(pos)\n",
    "        pos_emb = pos_emb * self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            # Apply the mask to ignore padded positions\n",
    "            pos_emb = pos_emb * mask\n",
    "            \n",
    "        return l2norm(pos_emb) if self.l2norm_embed else pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=278):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model%2 != 0:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)[:,0:-1]\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to(device)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        pos_enc = self.pe[:, :x.size(1)]\n",
    "        if not(mask == None):\n",
    "            mask = mask.to(device)\n",
    "            pos_enc = pos_enc*mask\n",
    "        return x + pos_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e4065",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f7ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinguisticFeature = Callable[[Tuple[str]], Tuple[torch.Tensor]]\n",
    "\n",
    "# def apply_standardization(x, m, sd):\n",
    "#     nonzero_sd = sd.clone()\n",
    "#     nonzero_sd[sd == 0] = 1\n",
    "#     x = torch.from_numpy(x).float()\n",
    "#     res = (x - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "#     return res\n",
    "\n",
    "def apply_standardization(x, m, sd):\n",
    "    nonzero_sd = sd.clone()\n",
    "    nonzero_sd[sd == 0] = 1\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x_zeros = x[x.sum(dim=(1)) == 0]\n",
    "    x_zeros[x_zeros==0] = -5\n",
    "    x_non_zeros = x[x.sum(dim=(1)) != 0]\n",
    "    x_non_zeros = (x_non_zeros - m.unsqueeze(0)) / nonzero_sd.unsqueeze(0)\n",
    "    res = torch.cat((x_non_zeros, x_zeros), axis =0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def aggregate_per_subject(subjs, y_preds, y_preds_class, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_preds_class_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_class_subj = y_preds_class[subjs == subj]\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "        if sum(y_pred_class_subj) >= (len(y_pred_class_subj) / 2):\n",
    "            y_preds_class_subj.append(1)\n",
    "        else:\n",
    "            y_preds_class_subj.append(0)\n",
    "    return subjs_subj, y_preds_subj, y_preds_class_subj, y_trues_subj\n",
    "\n",
    "def getmeansd(dataset, batch: bool = False):  # removing rows of 0s\n",
    "    if batch:\n",
    "        # Anna added preprocessing from ndarray to torch\n",
    "        tensors = [X for X, _, _, _ in dataset]  #torch.from_numpy(X).float()\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=(1,2)) != 0]   #tensors[tensors.sum(dim=(1, 2)) != 0]\n",
    "        # remove rows of 0s from the computation\n",
    "        sentences, timesteps, features = tensors.size()\n",
    "        subset = tensors.sum(dim=(2)) != 0\n",
    "        subset = subset.view(sentences, timesteps, 1)\n",
    "        subset = subset.expand(sentences, timesteps, features)\n",
    "        result = tensors[subset].view(-1, features) \n",
    "        \n",
    "        means = torch.mean(result, dim=(0))\n",
    "        sd = torch.std(result, dim=(0))\n",
    "        return means, sd\n",
    "    else:\n",
    "        tensors = [torch.from_numpy(X).float() for X, _, _, _ in dataset] # Anna added , was [X for X, _, _ in dataset]\n",
    "        tensors = torch.cat(tensors, axis=0)\n",
    "        # remove padded tensors\n",
    "        tensors = tensors[tensors.sum(dim=1) != 0]\n",
    "        means = torch.mean(tensors, 0)\n",
    "        sd = torch.std(tensors, 0)\n",
    "        return means, sd\n",
    "    \n",
    "    \n",
    "def get_params(paramdict) -> dict:\n",
    "    selected_pars = dict()\n",
    "    for k in paramdict:\n",
    "        selected_pars[k] = random.sample(list(paramdict[k]), 1)[0]\n",
    "    return selected_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81deb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_speed_per_subject(subjs, y_preds, y_trues):\n",
    "    y_preds = np.array(y_preds)\n",
    "    #y_preds_class = np.array(y_preds_class)\n",
    "    y_trues = np.array(y_trues)\n",
    "    subjs = np.array(subjs).flatten()\n",
    "    y_preds_subj = []\n",
    "    y_trues_subj = []\n",
    "    subjs_subj = np.unique(subjs)\n",
    "    for subj in subjs_subj:\n",
    "        subj = subj.item()\n",
    "        y_pred_subj = y_preds[subjs == subj]\n",
    "        y_true_subj = y_trues[subjs == subj]\n",
    "        assert len(np.unique(y_true_subj)) == 1, f\"No unique label: subj={subj}\"\n",
    "        y_trues_subj.append(np.unique(y_true_subj).item())\n",
    "        y_preds_subj.append(np.mean(y_pred_subj).item())\n",
    "\n",
    "    return subjs_subj, y_preds_subj, y_trues_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e747c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataPreprocessor(Dataset):\n",
    "    \"\"\"Dataset with the long-format sequence of fixations made during reading by dyslexic \n",
    "    and normally-developing Russian-speaking monolingual children.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        csv_file, \n",
    "        transform=None, \n",
    "        target_transform=None, \n",
    "        dropPhonologyFeatures = True, \n",
    "        dropPhonologySubjects = True,     \n",
    "        num_folds: float = 10,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on a label.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # changing dyslexia labels to 0 and 1\n",
    "        data['group'] = data['group'] + 0.5\n",
    "        \n",
    "        # log-transforming frequency\n",
    "        to_transform = ['frequency', 'predictability', 'fix_dur'] #\n",
    "        for column in to_transform:\n",
    "            data[column] = data[column].apply(lambda x: np.log(x) if x > 0 else 0) \n",
    "        \n",
    "        # drop columns we don't use\n",
    "        data = data.drop(columns = ['fix_x', 'fix_y', 'fix_index'])  \n",
    "        \n",
    "        # center reading sopeed in case we need to predict it\n",
    "        data['Reading_speed'] = (data['Reading_speed'] - data['Reading_speed'].mean())/data['Reading_speed'].std(ddof=0)\n",
    "        \n",
    "        if ablation == True:\n",
    "            data = data.drop(columns = ['sex', 'Grade'])\n",
    "            convert_columns = ['direction']\n",
    "        else:\n",
    "            convert_columns = ['Grade', 'direction'] \n",
    "        \n",
    "        if dropPhonologyFeatures == True:\n",
    "            data = data.drop(columns = ['IQ', 'Sound_detection', 'Sound_change'])\n",
    "        \n",
    "        for column in convert_columns:\n",
    "            prefix = column + '_dummy'\n",
    "            data = pd.concat([data, pd.get_dummies(data[column], \n",
    "                                    prefix=prefix)], axis=1)\n",
    "            data = data.drop(columns = column)\n",
    "        #data = data.drop(columns = ['Grade_dummy_0', 'direction_dummy_0'])\n",
    "            \n",
    "        if dropPhonologySubjects == True:\n",
    "            # Drop subjects\n",
    "            data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "        else:\n",
    "            # Drop columns\n",
    "            data.dropna(axis = 1, how = 'any', inplace = True)\n",
    "            \n",
    "        # rearrange columns (I need demogrpahic information to come last)\n",
    "#         cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur', 'landing', 'word_length',\n",
    "#                  'predictability', 'frequency', 'number.morphemes', 'next_fix_dist',\n",
    "#                  'sac_ampl', 'sac_angle', 'sac_vel', 'rel.position', 'direction_dummy_DOWN',\n",
    "#                  'direction_dummy_LEFT', 'direction_dummy_RIGHT', 'direction_dummy_UP',\n",
    "#                  'sex', 'Age', 'Grade_dummy_1', 'Grade_dummy_2', 'Grade_dummy_3', 'Grade_dummy_4',\n",
    "#                  'Grade_dummy_5', 'Grade_dummy_6']\n",
    "        cols = ['item', 'subj', 'group', 'Reading_speed', 'fix_dur',\n",
    "               'landing', 'word_length', 'predictability', 'frequency', \n",
    "                'number.morphemes', 'next_fix_dist', 'sac_ampl', 'sac_angle', \n",
    "                'sac_vel', 'rel.position', 'direction_dummy_LEFT', \n",
    "                'direction_dummy_RIGHT', 'direction_dummy_DOWN'] # temporary\n",
    "        data = data[cols]\n",
    "        \n",
    "        # Record features that are used for prediction\n",
    "        self._features = [i for i in data.columns if i not in ['group', 'item', 'subj', 'Reading_speed']]\n",
    "        self._data = pd.DataFrame()\n",
    "        # Add sentence IDs and subject IDs\n",
    "        self._data[\"sn\"] = data[\"item\"]\n",
    "        self._data[\"subj\"] = data[\"subj\"]\n",
    "        # Add labels\n",
    "        self._data[\"group\"] = data[\"group\"]\n",
    "        self._data[\"reading_speed\"] = data[\"Reading_speed\"]\n",
    "        \n",
    "        # Add features used for prediction\n",
    "        for feature in self._features:\n",
    "            self._data[feature] = data[feature]\n",
    "\n",
    "        # Distribute subjects across stratified folds\n",
    "        self._num_folds = num_folds\n",
    "        self._folds = [[] for _ in range(num_folds)]\n",
    "        dyslexic_subjects = self._data[self._data[\"group\"] == 1][\"subj\"].unique()\n",
    "        control_subjects = self._data[self._data[\"group\"] == 0][\"subj\"].unique()\n",
    "        random.shuffle(dyslexic_subjects)\n",
    "        random.shuffle(control_subjects)\n",
    "        for i, subj in enumerate(dyslexic_subjects):\n",
    "            self._folds[i % num_folds].append(subj)\n",
    "        for i, subj in enumerate(control_subjects):\n",
    "            self._folds[num_folds - 1 - i % num_folds].append(subj)\n",
    "        for fold in self._folds:\n",
    "            random.shuffle(fold)\n",
    "\n",
    "    def _iter_trials(self, folds: Collection[int]) -> Iterator[pd.DataFrame]:\n",
    "        # Iterate over all folds\n",
    "        for fold in folds:\n",
    "            # Iterate over all subjects in the fold\n",
    "            for subj in self._folds[fold]:       # Anna: subj in fold?\n",
    "                subj_data = self._data[self._data[\"subj\"] == subj]\n",
    "                # Iterate over all sentences this subject read\n",
    "                for sn in subj_data[\"sn\"].unique():\n",
    "                    trial_data = subj_data[subj_data[\"sn\"] == sn]\n",
    "                    yield trial_data\n",
    "                    \n",
    "                    \n",
    "    def iter_folds(\n",
    "        self, folds: Collection[int]) -> Iterator[Tuple[torch.Tensor, torch.Tensor, int]]:\n",
    "        for trial_data in self._iter_trials(folds):\n",
    "            predictors = trial_data[self._features].to_numpy()\n",
    "            #predictors = np.reshape(predictors, (int(len(predictors)/278), 278, predictors.shape[1]))\n",
    "            label = trial_data[\"group\"].unique().item()\n",
    "            subj = trial_data[\"subj\"].unique().item()\n",
    "            reading_speed = trial_data[\"reading_speed\"].unique().item()\n",
    "            #  X = (time_steps, features)\n",
    "            X = predictors\n",
    "            y = torch.tensor(label, dtype=torch.float)\n",
    "            rs = torch.tensor(reading_speed , dtype=torch.float)\n",
    "            yield X, y, subj, rs\n",
    "                    \n",
    "\n",
    "    @property\n",
    "    def num_features(self) -> int:\n",
    "        \"\"\"Number of features per word (excluding word vector dimensions).\"\"\"\n",
    "        return len(self._features)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def max_number_of_sentences(self):\n",
    "        data_copy = self._data.copy()\n",
    "        max_s_count = data_copy.groupby(by=\"subj\").sn.unique()\n",
    "        return max([len(x) for x in max_s_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c918bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyetrackingDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprocessor: EyetrackingDataPreprocessor,\n",
    "       # word_vector_model: WordVectorModel,\n",
    "        folds: Collection[int],\n",
    "        batch_subjects: bool = False,\n",
    "    ):\n",
    "        self.sentences = list(preprocessor.iter_folds(folds))\n",
    "        self._subjects = list(np.unique([subj for _, _, subj, _ in self.sentences]))\n",
    "        self.num_features = preprocessor.num_features# + word_vector_model.dimensions()\n",
    "        self.batch_subjects = batch_subjects\n",
    "        #self.max_sentence_length = preprocessor.max_sentence_length\n",
    "        self.max_number_of_sentences = preprocessor.max_number_of_sentences\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        if self.batch_subjects:\n",
    "            subject = self._subjects[index]\n",
    "            subject_sentences = [\n",
    "                (X, y, subj, rs) for X, y, subj, rs in self.sentences if subj == subject\n",
    "            ]\n",
    "            X = torch.stack([torch.FloatTensor(X) for X, _, _, _ in subject_sentences]) #[X for X, _, _ in subject_sentences] #torch.FloatTensor([X for X, _, _ in subject_sentences])\n",
    "            y = torch.stack([y for _, y, _, _ in subject_sentences]).unique().squeeze() \n",
    "            rs = torch.stack([rs for _, _, _, rs in subject_sentences]).unique().squeeze()\n",
    "            return X, y, subject, rs\n",
    "\n",
    "        else:\n",
    "            X, y, subj, rs = self.sentences[index]\n",
    "            #X = torch.from_numpy(X).float()   \n",
    "            return X, y, subj, rs\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.batch_subjects:\n",
    "            return len(self._subjects)\n",
    "        else:\n",
    "            return len(self.sentences)\n",
    "\n",
    "    def standardize(self, mean: torch.Tensor, sd: torch.Tensor):\n",
    "        self.sentences = [\n",
    "            (apply_standardization(X, mean, sd), y, subj, rs)\n",
    "            for X, y, subj, rs in self.sentences\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9034822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annas changes\n",
    "class TransformerWithCustomPositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embed_dim = 30,\n",
    "        d_model = 2,\n",
    "        inner_dim = 8,\n",
    "        num_heads = 1, \n",
    "        num_layers = 1, \n",
    "        dropout = 0,\n",
    "        mask_prob = 0.2,\n",
    "        replace_prob = 0, # 0.9\n",
    "        mask_token_id = 2,\n",
    "        pad_token_id = -5,\n",
    "        mask_ignore_token_ids = []\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.d_model = d_model\n",
    "        self.inner_dim = inner_dim\n",
    "        self.mask_prob = mask_prob\n",
    "        self.replace_prob = replace_prob\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # token ids\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.d_model, \n",
    "                                                      max_len=self.embed_dim)\n",
    "      #  self.positional_encoding = AbsolutePositionalEmbedding(dim = self.d_model)\n",
    "        self.positional_encoding = CustomPositionalEncoding(fixations = self.embed_dim, \n",
    "                                                            features = self.d_model)\n",
    "        self.transformer = nn.MultiheadAttention(embed_dim = self.d_model,  \n",
    "                                                 num_heads = self.num_heads, \n",
    "                                                 bias = True,\n",
    "                                                 batch_first = True)\n",
    "        # Output classifier per sequence lement\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.inner_dim),\n",
    "            nn.LayerNorm(self.inner_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.inner_dim, self.d_model)\n",
    "        )\n",
    "        \n",
    "    # TransformerEncoder\n",
    "    def forward(self, seq):\n",
    "        # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "        # also do not include these special tokens in the tokens chosen at random\n",
    "        no_mask = mask_with_tokens_3D(seq, self.mask_ignore_token_ids) \n",
    "        mask = get_mask_subset_with_prob_3D(~no_mask, self.mask_prob)\n",
    "        hidden = no_mask + mask # all elements that the model will not attend to\n",
    "\n",
    "        # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
    "        masked_seq = seq.clone().detach().to(device)\n",
    "        \n",
    "        #   Static positional encoding\n",
    "        masked_seq_pos = self.positional_encoding(masked_seq, mask = None) #for hidden fixations ~ no_mask\n",
    "\n",
    "        #[mask] input\n",
    "        masked_replace_prob = prob_mask_like_3D(seq, self.replace_prob) # Anna: select 90% of all values  (ignore all masking for now)\n",
    "        masked_seq = masked_seq_pos.masked_fill(mask * masked_replace_prob, self.mask_token_id) # Anna: select 90% only of those selected for masking\n",
    "        \n",
    "        # derive labels to predict\n",
    "        labels = seq.masked_fill(~mask, self.pad_token_id)\n",
    "        \n",
    "        #import pdb; \n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # Pass through the transformer\n",
    "        x, weights = self.transformer(masked_seq, \n",
    "                                      key = masked_seq, \n",
    "                                      value = masked_seq, \n",
    "                                      key_padding_mask = hidden[:,:,0])  #no_mask// for masking out fixations: hidden[:,:,0]\n",
    "        \n",
    "        preds = self.output_net(x)\n",
    "        \n",
    "        # may add loss\n",
    "\n",
    "        return x, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cc4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "test_fold = 3\n",
    "dev_fold = 2\n",
    "train_folds = [\n",
    "                fold\n",
    "                for fold in range(NUM_FOLDS)\n",
    "                if fold != test_fold and fold != dev_fold\n",
    "            ]\n",
    "\n",
    "preprocessor = EyetrackingDataPreprocessor(\n",
    "    csv_file = 'data/30fixations_no_padding_sentence_word_pos.csv', # 'data/fixation_dataset_30fix_padded.csv',  \n",
    "    num_folds = NUM_FOLDS\n",
    ")\n",
    "\n",
    "train_dataset = EyetrackingDataset(\n",
    "                preprocessor,\n",
    "                folds=train_folds,\n",
    "                batch_subjects=BATCH_SUBJECTS,\n",
    "            )\n",
    "mean, sd = getmeansd(train_dataset, batch=BATCH_SUBJECTS)\n",
    "train_dataset.standardize(mean, sd)\n",
    "dev_dataset = EyetrackingDataset(\n",
    "    preprocessor,\n",
    "    folds=[dev_fold],\n",
    "    batch_subjects=BATCH_SUBJECTS,\n",
    ")\n",
    "dev_dataset.standardize(mean, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6550, Test Loss: 0.5569\n",
      "Epoch 51: Train Loss: 0.0840, Test Loss: 0.1024\n",
      "Epoch 101: Train Loss: 0.0812, Test Loss: 0.1124\n",
      "Epoch 151: Train Loss: 0.0782, Test Loss: 0.0903\n",
      "Epoch 201: Train Loss: 0.0791, Test Loss: 0.0850\n",
      "Epoch 251: Train Loss: 0.0794, Test Loss: 0.1052\n",
      "Epoch 301: Train Loss: 0.0785, Test Loss: 0.0882\n",
      "Epoch 351: Train Loss: 0.0779, Test Loss: 0.0833\n"
     ]
    }
   ],
   "source": [
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2)\n",
    "test_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "trainer = TransformerWithCustomPositionalEncoding(embed_dim = 30,\n",
    "                                                  num_heads = 14, \n",
    "                                                  d_model = NUM_FEATURES,\n",
    "                                                  num_layers= 1).to(device)\n",
    "\n",
    "# # Setup optimizer to optimize model's parameters\n",
    "optimizer = Adam(trainer.parameters(), lr=3e-3)\n",
    "\n",
    "epochs = 700\n",
    "epoch_count = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_count += 1\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle = True)\n",
    "    train_loss = 0\n",
    "    trainer.train()\n",
    "    ### Training\n",
    "    for X, _, _, _ in train_loader:\n",
    "\n",
    "        # 1. Forward pass \n",
    "        X = X.to(device)\n",
    "\n",
    "        train_preds, labels, mask = trainer(X)\n",
    "            \n",
    "        # 2. Calculate loss/accuracy\n",
    "\n",
    "        loss = mse_loss(\n",
    "            labels,\n",
    "            train_preds,\n",
    "            mask\n",
    "        )\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss = epoch_loss/(len(train_loader.dataset)/BATCH_SIZE)\n",
    "\n",
    "    #### Evaluation\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    trainer.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_test, _, _, _ in test_loader:\n",
    "            X_test = X_test.to(device)\n",
    "            test_preds, labels, mask = trainer(X_test)\n",
    "            tloss = mse_loss(\n",
    "                labels,\n",
    "                test_preds,\n",
    "                mask\n",
    "            )\n",
    "            test_loss += tloss.item() \n",
    "\n",
    "    test_loss = test_loss /(len(test_loader.dataset)/BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "#print('Input: ', X[0, 0:15])\n",
    "#print('Predictions: ', train_preds[0, 0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3113b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse_loss(\n",
    "    labels,\n",
    "    test_preds,\n",
    "    mask\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[3,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[7][0:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
